{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e075070-2a02-4214-a5bd-ef7542ec9c25",
   "metadata": {},
   "source": [
    "# LSTM Tutorial\n",
    "Implementing LSTM based on a tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f4f863f9-cfaa-479b-b1b2-7582b3156ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "import time \n",
    "from typing import Optional\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ray import tune\n",
    "from ray.tune import JupyterNotebookReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e6f0444-c434-40fd-a301-88f181fd353b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydantic\n",
      "  Downloading pydantic-1.9.1-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "     ---------------------------------------- 2.0/2.0 MB 10.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\spenc\\appdata\\local\\pypoetry\\cache\\virtualenvs\\bgpredict-zzmw8ikr-py3.10\\lib\\site-packages (from pydantic) (4.3.0)\n",
      "Installing collected packages: pydantic\n",
      "Successfully installed pydantic-1.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7392d198-c375-4835-b83f-af62e7223b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "366f8377-77cc-4058-9340-4ab92ea50dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing Functions\n",
    "def load_data_to_df():\n",
    "    location = f\"postgresql://postgres:{os.environ.get('db_password')}@{os.environ.get('db_location')}\"\n",
    "    engine = create_engine(location)\n",
    "    conn = engine.connect()\n",
    "    raw_df = pd.read_sql(\"select * from public.vw_final_dataset where subjectid = 2033176\", conn)\n",
    "    if raw_df.empty:\n",
    "        raise ValueError(\"empty df\")\n",
    "    return raw_df\n",
    "\n",
    "def clean_data(df):\n",
    "    # Drop rows with no Y value\n",
    "    df = df.dropna(subset='bg')\n",
    "    \n",
    "    # Sort by timestamp\n",
    "    df = df.sort_values(by=\"timestamp_clean\")\n",
    "    \n",
    "    # Set index to time_stamp_clean\n",
    "    df.index = df['timestamp_clean']\n",
    "    df = df.drop(labels=['timestamp_clean'], axis=1)\n",
    "    \n",
    "    # Drop first row by subject which has data quality issues\n",
    "    df = df[df.groupby('subjectid').cumcount() > 0] \n",
    "    \n",
    "    # Drop columns that are indices, irrelevant, or capture in OHE variables\n",
    "    drop_cols = ['subjectid', 'entryid', 'timestamp', 'date', 'time']\n",
    "    df = df.drop(labels=drop_cols, axis=1)\n",
    "    \n",
    "    # Fill nulls (lag BG values) with 0 to indicate data is unavailable\n",
    "    print(f\"Null values to be filled by column:\")\n",
    "    nulls = df.isna().sum()\n",
    "    null_idx = list(nulls.index)\n",
    "    vals = list(nulls)\n",
    "    for col, val in list(zip(null_idx, vals)):\n",
    "        if val > 0:\n",
    "            print(col,val)\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    # One hot Encode Weekdays\n",
    "    weekdays = np.unique(df['weekday'])\n",
    "    ohe_weekdays = [f\"ohe_{day}\" for day in weekdays]\n",
    "    df[ohe_weekdays] = pd.get_dummies(df.weekday)\n",
    "    df = df.drop(labels=\"weekday\", axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def split_and_scale(df):\n",
    "    # train/val/test split\n",
    "    train_df = df.loc[df['train_set'] ==1, :]\n",
    "    val_df = df.loc[df['validation_set'] ==1, :]\n",
    "    test_df = df.loc[df['test_set'] == 1, :] \n",
    "    \n",
    "    # Extract y vars\n",
    "    train_y = train_df['bg']\n",
    "    val_y = val_df['bg']\n",
    "    test_y = test_df['bg']\n",
    "    \n",
    "    # Drop non-X columns\n",
    "    drop_cols = ['train_set', 'validation_set', 'test_set', 'bg']\n",
    "    train_df = train_df.drop(labels=drop_cols, axis=1)\n",
    "    val_df = val_df.drop(labels=drop_cols, axis=1)\n",
    "    test_df = test_df.drop(labels=drop_cols, axis=1)\n",
    "    \n",
    "    # Select Scaling columns (i.e. don't scale one hot encoded variables)\n",
    "    ohe_cols = train_df.columns[train_df.columns.str.contains('ohe')]\n",
    "    scaling_cols = train_df.columns.difference(ohe_cols)\n",
    "    print(f\"{len(ohe_cols)} one hot encoded columns \")\n",
    "    print(f\"{len(scaling_cols)} scaled columns\")\n",
    "    \n",
    "    # Fit Scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(train_df[scaling_cols])\n",
    "    \n",
    "    # Perform Scaling \n",
    "    train_array = scaler.transform(train_df[scaling_cols])\n",
    "    val_array = scaler.transform(val_df[scaling_cols])\n",
    "    test_array = scaler.transform(test_df[scaling_cols])\n",
    "    \n",
    "    # Recombine Scaled Data into DataFrame Format \n",
    "    train_scaled_df = pd.DataFrame(train_array, columns=scaling_cols, index=train_df.index)\n",
    "    val_scaled_df = pd.DataFrame(val_array, columns=scaling_cols, index=val_df.index)\n",
    "    test_scaled_df = pd.DataFrame(test_array, columns=scaling_cols, index=test_df.index)\n",
    "    \n",
    "    train_df = pd.concat([train_scaled_df, train_df.loc[:,ohe_cols], train_y], axis=1)\n",
    "    val_df = pd.concat([val_scaled_df, val_df.loc[:,ohe_cols], val_y], axis=1)\n",
    "    test_df = pd.concat([test_scaled_df, test_df.loc[:,ohe_cols], test_y], axis=1)\n",
    "    \n",
    "#     dataset= DataSet(**{'train_df': train_df,\n",
    "#                         'val_df': val_df,\n",
    "#                         'test_df': test_df})\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "def df_to_Xy_tensors(df, window_size=12):\n",
    "    X = []\n",
    "    y = []\n",
    "    num_features = len(df.columns) - 1\n",
    "    for idx in range(window_size, len(df)-window_size):\n",
    "        window_df = df.iloc[idx-window_size:idx]\n",
    "        X.append(window_df.loc[:, df.columns != 'bg'].values)\n",
    "        # The first element is the y value associated with the sequence of X values \n",
    "        y.append(window_df['bg'].iloc[0])\n",
    "        \n",
    "    X_tensor = torch.cat([torch.tensor(i).float() for i in X]).view(len(X), window_size, num_features)\n",
    "    y_tensor = torch.tensor(y).float()\n",
    "    return X_tensor, y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "02ef3ab2-1043-4ada-84fc-de139aa37b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading\n",
      "cleaning\n",
      "Null values to be filled by column:\n",
      "bg_lag_1 83\n",
      "bg_lag_2 83\n",
      "bg_lag_3 85\n",
      "bg_lag_4 86\n",
      "bg_lag_5 86\n",
      "bg_lag_6 88\n",
      "bg_lag_7 89\n",
      "bg_lag_8 90\n",
      "bg_lag_9 91\n",
      "bg_lag_10 92\n",
      "bg_lag_11 92\n",
      "bg_lag_12 94\n",
      "split and scaling\n",
      "148 one hot encoded columns \n",
      "23 scaled columns\n",
      "converting to tensors\n"
     ]
    }
   ],
   "source": [
    "print('loading')\n",
    "raw_df = load_data_to_df()\n",
    "print('cleaning')\n",
    "clean_df = clean_data(raw_df)\n",
    "print(\"split and scaling\")\n",
    "train_df, val_df, test_df = split_and_scale(clean_df)\n",
    "print(\"converting to tensors\")\n",
    "tensorset = TensorSet()\n",
    "train_X, train_y = df_to_Xy_tensors(train_df, window_size=12)\n",
    "val_X, val_y = df_to_Xy_tensors(val_df, window_size=12)\n",
    "test_X, test_y = df_to_Xy_tensors(test_df, window_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8f5270fd-3569-45c1-b338-f1f8331e79c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24794, 12, 171])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([24794])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1645b89f-675c-45ae-af65-b317ee6bef90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1   2019-01-14 19:51:35.780\n",
       "2   2019-01-14 19:54:15.583\n",
       "3   2019-01-14 20:01:34.543\n",
       "4   2019-01-14 20:06:34.364\n",
       "5   2019-01-14 20:16:34.036\n",
       "Name: timestamp_clean, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.sort_values('timestamp_clean')['timestamp_clean'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ecb33b57-17c4-4206-ac09-2360e3060092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns: Index(['train_set', 'test_set', 'validation_set', 'weekday', 'hour', 'minute',\n",
      "       'federal_holiday', 'bg', 'insulin', 'carbs',\n",
      "       'datediff_currentbg_lastbg_inseconds', 'bg_lag_1', 'bg_lag_2',\n",
      "       'bg_lag_3', 'bg_lag_4', 'bg_lag_5', 'bg_lag_6', 'bg_lag_7', 'bg_lag_8',\n",
      "       'bg_lag_9', 'bg_lag_10', 'bg_lag_11', 'bg_lag_12'],\n",
      "      dtype='object')\n",
      "shape: (54013, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_set</th>\n",
       "      <th>test_set</th>\n",
       "      <th>validation_set</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>federal_holiday</th>\n",
       "      <th>bg</th>\n",
       "      <th>insulin</th>\n",
       "      <th>carbs</th>\n",
       "      <th>...</th>\n",
       "      <th>bg_lag_3</th>\n",
       "      <th>bg_lag_4</th>\n",
       "      <th>bg_lag_5</th>\n",
       "      <th>bg_lag_6</th>\n",
       "      <th>bg_lag_7</th>\n",
       "      <th>bg_lag_8</th>\n",
       "      <th>bg_lag_9</th>\n",
       "      <th>bg_lag_10</th>\n",
       "      <th>bg_lag_11</th>\n",
       "      <th>bg_lag_12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp_clean</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-14 20:01:34.543</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-14 20:06:34.364</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-14 20:16:34.036</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-14 20:26:34.794</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>211.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-14 20:31:33.834</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>20.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>214.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         train_set  test_set  validation_set weekday  hour  \\\n",
       "timestamp_clean                                                              \n",
       "2019-01-14 20:01:34.543          1         0               0  Monday  20.0   \n",
       "2019-01-14 20:06:34.364          1         0               0  Monday  20.0   \n",
       "2019-01-14 20:16:34.036          1         0               0  Monday  20.0   \n",
       "2019-01-14 20:26:34.794          1         0               0  Monday  20.0   \n",
       "2019-01-14 20:31:33.834          1         0               0  Monday  20.0   \n",
       "\n",
       "                         minute  federal_holiday     bg  insulin  carbs  ...  \\\n",
       "timestamp_clean                                                          ...   \n",
       "2019-01-14 20:01:34.543     1.0                0  211.0      0.0    0.0  ...   \n",
       "2019-01-14 20:06:34.364     6.0                0  214.0      0.0    0.0  ...   \n",
       "2019-01-14 20:16:34.036    16.0                0  214.0      0.0    0.0  ...   \n",
       "2019-01-14 20:26:34.794    26.0                0  206.0      0.0    0.0  ...   \n",
       "2019-01-14 20:31:33.834    31.0                0  196.0      0.0    0.0  ...   \n",
       "\n",
       "                         bg_lag_3  bg_lag_4  bg_lag_5  bg_lag_6  bg_lag_7  \\\n",
       "timestamp_clean                                                             \n",
       "2019-01-14 20:01:34.543       0.0       0.0       0.0       0.0       0.0   \n",
       "2019-01-14 20:06:34.364       0.0       0.0       0.0       0.0       0.0   \n",
       "2019-01-14 20:16:34.036     201.0       0.0       0.0       0.0       0.0   \n",
       "2019-01-14 20:26:34.794     211.0     201.0       0.0       0.0       0.0   \n",
       "2019-01-14 20:31:33.834     214.0     211.0     201.0       0.0       0.0   \n",
       "\n",
       "                         bg_lag_8  bg_lag_9  bg_lag_10  bg_lag_11  bg_lag_12  \n",
       "timestamp_clean                                                               \n",
       "2019-01-14 20:01:34.543       0.0       0.0        0.0        0.0        0.0  \n",
       "2019-01-14 20:06:34.364       0.0       0.0        0.0        0.0        0.0  \n",
       "2019-01-14 20:16:34.036       0.0       0.0        0.0        0.0        0.0  \n",
       "2019-01-14 20:26:34.794       0.0       0.0        0.0        0.0        0.0  \n",
       "2019-01-14 20:31:33.834       0.0       0.0        0.0        0.0        0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Clean Data\n",
    "\n",
    "def clean_data(df):\n",
    "    # Drop rows with no Y value\n",
    "    df = raw_df.dropna(subset='bg')\n",
    "    \n",
    "    # Sort by timestamp\n",
    "    df = df.sort_values(by=\"timestamp_clean\")\n",
    "    \n",
    "    # Set index to time_stamp_clean\n",
    "    df.index = df['timestamp_clean']\n",
    "    df = df.drop(labels=['timestamp_clean'], axis=1)\n",
    "    \n",
    "    # Drop first row by subject which has data quality issues\n",
    "    df = df[df.groupby('subjectid').cumcount() > 0] \n",
    "    df = df.drop(labels=['num_in_group'])\n",
    "    \n",
    "    # Drop columns that are indices, irrelevant, or capture in OHE variables\n",
    "    drop_cols = ['subjectid', 'entryid', 'timestamp', 'date', 'time']\n",
    "    df = df.drop(labels=drop_cols, axis=1)\n",
    "    \n",
    "    # Fill nulls (lag BG values) with 0 to indicate data is unavailable\n",
    "    print(f\"Null values to be filled by column: {df.isna().sum()}\")\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    # One hot Encode Weekdays\n",
    "    weekdays = np.unique(df['weekday'])\n",
    "    ohe_weekdays = [f\"ohe_{day}\" for day in weekdays]\n",
    "    df[ohe_weekdays] = pd.get_dummies(df.weekday)\n",
    "    df = df.drop(labels=\"weekday\", axis=1)\n",
    "    \n",
    "    return df \n",
    "    \n",
    "# Drop rows with no Y value\n",
    "df = raw_df.dropna(subset='bg')\n",
    "\n",
    "# Sort by timestamp\n",
    "df = df.sort_values(by=\"timestamp_clean\")\n",
    "\n",
    "# Set index to time_stamp_clean\n",
    "df.index = df['timestamp_clean']\n",
    "df = df.drop(labels=['timestamp_clean'], axis=1)\n",
    "\n",
    "# Drop first row which has data quality issues\n",
    "df = df.iloc[1:len(df), :] \n",
    "\n",
    "# Drop one hot encoded (OHE) columns which contain no relevant information for single subjects\n",
    "df = df.loc[:, ~df.columns.str.contains('ohe')]\n",
    "\n",
    "# Drop other columns that contain no relevant info for single subjects\n",
    "single_subj_drop_cols = ['carbs_datacount', 'normalized_carbs_datapercentile', 'normalized_insulin_datapercentile',\n",
    "                         'insulin_datacount', 'observations']\n",
    "df = df.drop(labels=single_subj_drop_cols, axis=1)\n",
    "\n",
    "# Drop columns that are indices, irrelevant, or capture in OHE variables\n",
    "drop_cols = ['subjectid', 'entryid', 'timestamp', 'date', 'time']\n",
    "df = df.drop(labels=drop_cols, axis=1)\n",
    "\n",
    "# Fill nulls (lag BG values) with 0 to indicate data is unavailable\n",
    "df = df.fillna(0)\n",
    "\n",
    "print(f\"columns: {df.columns}\")\n",
    "print(f\"shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bdc491ee-6410-4fdb-bc6d-07d2d5f80e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\spenc\\AppData\\Local\\Temp\\ipykernel_11176\\771581302.py:1: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  train_df.columns[list(train_df.columns.str.contains('ohe')).append('bg')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['weekday', 'hour', 'minute', 'federal_holiday', 'insulin',\n",
       "        'carbs', 'datediff_currentbg_lastbg_inseconds', 'bg_lag_1',\n",
       "        'bg_lag_2', 'bg_lag_3', 'bg_lag_4', 'bg_lag_5', 'bg_lag_6',\n",
       "        'bg_lag_7', 'bg_lag_8', 'bg_lag_9', 'bg_lag_10', 'bg_lag_11',\n",
       "        'bg_lag_12']], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns[list(train_df.columns.str.contains('ohe')).append('bg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a79b074-9195-4d74-ae7f-a65101be434f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one hot encoded columns: Index([], dtype='object')\n",
      "scaling columns: Index(['weekday', 'hour', 'minute', 'federal_holiday', 'insulin', 'carbs',\n",
      "       'datediff_currentbg_lastbg_inseconds', 'bg_lag_1', 'bg_lag_2',\n",
      "       'bg_lag_3', 'bg_lag_4', 'bg_lag_5', 'bg_lag_6', 'bg_lag_7', 'bg_lag_8',\n",
      "       'bg_lag_9', 'bg_lag_10', 'bg_lag_11', 'bg_lag_12'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Monday'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 85>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaling columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscaling_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     84\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m---> 85\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mscaling_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m train_array \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(train_df[scaling_cols])\n\u001b[0;32m     88\u001b[0m val_array \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(val_df[scaling_cols])\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bgpredict-zZmw8Ikr-py3.10\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:420\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bgpredict-zZmw8Ikr-py3.10\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:457\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMinMaxScaler does not support sparse input. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider using MaxAbsScaler instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    454\u001b[0m     )\n\u001b[0;32m    456\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 457\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_pass\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m data_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmin(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    465\u001b[0m data_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmax(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bgpredict-zZmw8Ikr-py3.10\\lib\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bgpredict-zZmw8Ikr-py3.10\\lib\\site-packages\\sklearn\\utils\\validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    854\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 856\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    860\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bgpredict-zZmw8Ikr-py3.10\\lib\\site-packages\\pandas\\core\\generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2063\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Monday'"
     ]
    }
   ],
   "source": [
    "## Preprocessing \n",
    "\n",
    "# train/val/test split\n",
    "train_df = df.loc[df['train_set'] ==1, :]\n",
    "val_df = df.loc[df['validation_set'] ==1, :]\n",
    "test_df = df.loc[df['test_set'] == 1, :] \n",
    "\n",
    "# Extract Y vars\n",
    "train_y = train_df['bg']\n",
    "val_y = val_df['bg']\n",
    "test_y = test_df['bg']\n",
    "\n",
    "# Drop non-X columns\n",
    "drop_cols = ['train_set', 'validation_set', 'test_set', 'bg']\n",
    "train_df = train_df.drop(labels=drop_cols, axis=1)\n",
    "val_df = val_df.drop(labels=drop_cols, axis=1)\n",
    "test_df = test_df.drop(labels=drop_cols, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "## Scaling \n",
    "# select scaling columns\n",
    "ohe_cols = train_df.columns[train_df.columns.str.contains('ohe')]\n",
    "scaling_cols = train_df.columns.difference(ohe_cols)\n",
    "print(f\"one hot encoded columns: {ohe_cols}\")\n",
    "print(f\"scaling columns: {scaling_cols}\")\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_df[scaling_cols])\n",
    "\n",
    "train_array = scaler.transform(train_df[scaling_cols])\n",
    "val_array = scaler.transform(val_df[scaling_cols])\n",
    "test_array = scaler.transform(test_df[scaling_cols])\n",
    "\n",
    "train_scaled_df = pd.DataFrame(train_array, columns=scaling_cols, index=train_df.index)\n",
    "val_scaled_df = pd.DataFrame(val_array, columns=scaling_cols, index=val_df.index)\n",
    "test_scaled_df = pd.DataFrame(test_array, columns=scaling_cols, index=test_df.index)\n",
    "\n",
    "train_df = pd.concat([train_scaled_df, train_df.loc[:,ohe_cols], train_y], axis=1)\n",
    "val_df = pd.concat([val_scaled_df, val_df.loc[:,ohe_cols], val_y], axis=1)\n",
    "test_df = pd.concat([test_scaled_df, test_df.loc[:,ohe_cols], test_y], axis=1)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ebf0cf7-999b-405c-82e6-018723c182b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24794 24794\n"
     ]
    }
   ],
   "source": [
    "# Coerce data to tensor format \n",
    "# [tensor([[ 0.5066, -0.4809, -1.4510,  0.3720, -1.3251]])\n",
    "#[\n",
    "#  Tensor- [X_1, X_2, ..., X_n]_{t-z}\n",
    "#  ... \n",
    "#  Tensor- [X_1, X_2, ..., X_n]_{t-2}\n",
    "#  Tensor- [X_1, X_2, ..., X_n]_{t-1}\n",
    "#]\n",
    "\n",
    "def df_to_X(df, window_size_hrs=6):\n",
    "    # Y was extracted earlier...\n",
    "    X = []\n",
    "#     y = []\n",
    "    window_delta = pd.Timedelta(hours=3)\n",
    "    earliest_time = min(df.index) + window_delta\n",
    "    latest_time = max(df.index) - window_delta\n",
    "    i = 0\n",
    "    for idx in df[earliest_time:latest_time].index:\n",
    "        window_df = df[idx - window_delta:idx]\n",
    "#         y.append([float(window_df.loc[idx]['bg'])])\n",
    "        X.append(window_df.loc[:, df.columns != 'bg'].values)\n",
    "        i +=1 \n",
    "    \n",
    "#     y = np.array(y)\n",
    "    return X #,y\n",
    "\n",
    "def df_to_Xy_tensors(df, window_size=12):\n",
    "    X = []\n",
    "    y = []\n",
    "    for idx in range(window_size, len(df)-window_size):\n",
    "        window_df = df.iloc[idx-window_size:idx]\n",
    "        X.append(window_df.loc[:, df.columns != 'bg'].values)\n",
    "        # The first element is the y value associated with the sequence of X values \n",
    "        y.append(window_df['bg'].iloc[0])\n",
    "    return X, y\n",
    "\n",
    "# train_X = df_to_X(train_df, window_size_hrs=3)\n",
    "# val_X = df_to_X(val_df, window_size_hrs=3)\n",
    "# test_X = df_to_X(test_df, window_size_hrs=3)\n",
    "\n",
    "train_X_seq, train_y_seq = df_to_Xy(train_df, window_size=12)\n",
    "print(len(train_X_seq), len(train_y_seq))\n",
    "val_X_seq, val_y_seq = df_to_Xy(val_df, window_size=12)\n",
    "test_X_seq, test_y_seq = df_to_Xy(test_df, window_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9380411-b19d-4552-8158-7a9ea4c14861",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size=8, num_lstm_layers=1, dropout=0):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_lstm_layers,\n",
    "                            dropout=dropout)\n",
    "        self.fc1 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        x = self.fc1(lstm_out)\n",
    "        return x\n",
    "\n",
    "# net = Net(input_size=input_size)\n",
    "# net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7c648fdf-72c2-4f27-8efd-53f36f4f8f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(microseconds=372403)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = datetime.now()\n",
    "for i in range(10000000):\n",
    "    pass\n",
    "datetime.now() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e08d3d8d-235c-4b1a-b1b2-6a1ba78ed780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(config, checkpoint_dir=None):\n",
    "    # Configure the network and send it to the device\n",
    "    # Width of the dataframe - 1 for the y variable \n",
    "    \n",
    "    # Load and clean data\n",
    "    print('loading')\n",
    "    raw_df = load_data_to_df()\n",
    "    \n",
    "#     engine = create_engine(config['data_loc'])\n",
    "#     conn = engine.connect()\n",
    "#     raw_df = pd.read_sql(\"select * from public.vw_final_dataset where subjectid = 2033176\", conn)\n",
    "\n",
    "    print('cleaning')\n",
    "    clean_df = clean_data(raw_df)\n",
    "    print(\"split and scaling\")\n",
    "    train_df, val_df, test_df = split_and_scale(clean_df)\n",
    "    # Process data for a given window_size\n",
    "    print(\"converting to tensors\")\n",
    "    window_size = config['window_size']\n",
    "    train_X, train_y = df_to_Xy_tensors(train_df, window_size=window_size)\n",
    "    val_X, val_y = df_to_Xy_tensors(val_df, window_size=window_size)\n",
    "    test_X, test_y = df_to_Xy_tensors(test_df, window_size=window_size)\n",
    "    print(\"Data processing finished\")\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "\n",
    "    train_X.to(device)\n",
    "    train_y.to(device)\n",
    "    val_X.to(device)\n",
    "    val_y.to(device)\n",
    "    \n",
    "    input_size = train_df.shape[1]-1\n",
    "    net = Net(input_size=input_size,\n",
    "              hidden_size=config['hidden_size'],\n",
    "              num_lstm_layers=config['num_lstm_layers'],\n",
    "              dropout=config['dropout'])\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        net = nn.DataParallel(net)     \n",
    "    net.to(device)\n",
    "    \n",
    "    \n",
    "    optimizer = optim.Adam(net.parameters(), lr=config['learning_rate'])\n",
    "    \n",
    "    # Checkpoint Dir Stuff -- handled by Tune \n",
    "    if checkpoint_dir:\n",
    "        checkpoint = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "        model_state, optimizer_state = torch.load(checkpoint)\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)    \n",
    "    \n",
    "    # train\n",
    "    BATCH_SIZE = config['batch_size']\n",
    "    for epoch in range(config['epoch']):\n",
    "        epoch_start = datetime.now()\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        running_loss = 0\n",
    "        epoch_steps = 0\n",
    "        for i in range(0, len(train_X)-BATCH_SIZE, BATCH_SIZE):\n",
    "            X = train_X[i:i+BATCH_SIZE]\n",
    "            y = train_y[i:i+BATCH_SIZE]\n",
    "            net.zero_grad()\n",
    "            \n",
    "            out_seq = net(X)\n",
    "            first_dim, second_dim, _ = out_seq.shape\n",
    "            pred = out_seq.view(first_dim, second_dim)[:, -1]\n",
    "            loss = F.mse_loss(pred, y)\n",
    "            loss.backward()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "            \n",
    "            # Print loss every 1000 batches\n",
    "            if i % 1000 == 999:\n",
    "                avg_loss = running_loss / epoch_steps\n",
    "                print(f\"Epoch {epoch}, steps {epoch_steps-1000}:{epoch_steps} avg loss: {avg_loss}\")\n",
    "                running_loss = 0 \n",
    "                \n",
    "        # Validate each epoch\n",
    "        val_loss = 0\n",
    "        val_steps = 0\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(val_X)-BATCH_SIZE, BATCH_SIZE):\n",
    "                X = val_X[i:i+BATCH_SIZE]\n",
    "                y = val_y[i:i+BATCH_SIZE]\n",
    "                out_seq = net(X)\n",
    "                first_dim, second_dim, _ = out_seq.shape\n",
    "                pred = out_seq.view(first_dim, second_dim)[:, -1]\n",
    "                loss = F.mse_loss(pred, y)\n",
    "                val_loss += loss.item()\n",
    "                val_steps += 1\n",
    "        \n",
    "        with tune.checkpoint_dir(step=epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "            \n",
    "        tune.report(val_loss=(val_loss/val_steps), train_loss=(running_loss/epoch_steps))\n",
    "        print(f\"Finished epoch {epoch} in {datetime.now()-epoch_start}\")\n",
    "    print(\"finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8b179097-00c4-483d-993d-af3d4c0914fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5173e55b-5c77-4fb6-8616-f476def12497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage stats collection is enabled by default for nightly wheels. To disable this, run the following command: `ray disable-usage-stats` before starting Ray. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.10.1</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 3.0.0.dev0</b></td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.10.1', ray_version='3.0.0.dev0', ray_commit='00947fd949624f8473ac33929f426fbf2846e91a', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': 'tcp://127.0.0.1:55253', 'raylet_socket_name': 'tcp://127.0.0.1:61264', 'webui_url': '', 'session_dir': 'C:\\\\Users\\\\spenc\\\\AppData\\\\Local\\\\Temp\\\\ray\\\\session_2022-07-21_17-13-48_881570_28504', 'metrics_export_port': 63033, 'gcs_address': '127.0.0.1:63604', 'address': '127.0.0.1:63604', 'dashboard_agent_listen_port': 52365, 'node_id': 'bfddd2cd8f6a70bb41481c9d9acd19ce34a068e1788a43d116c1c486'})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1713c5b7-769a-4c98-bda8-48103fb381d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-21 17:14:49 (running for 00:00:56.39)<br>Memory usage on this node: 9.6/11.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/1.68 GiB heap, 0.0/0.84 GiB objects<br>Result logdir: C:\\Users\\spenc\\ray_results\\train_lstm_2022-07-21_17-13-53<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">  hidden_size</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  num_lstm_layers</th><th style=\"text-align: right;\">  window_size</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_lstm_06101_00000</td><td>TERMINATED</td><td>127.0.0.1:25720</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">      0.0248484</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">            6</td><td style=\"text-align: right;\">   17120.2</td><td style=\"text-align: right;\">                   2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m loading\n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m cleaning\n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m Null values to be filled by column:\n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m bg_lag_1 83\n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m bg_lag_2 83\n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m bg_lag_3 85\n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m bg_lag_4 86\n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m bg_lag_5 86\n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m bg_lag_6 88\n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m bg_lag_7 89\n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m bg_lag_8 90\n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m bg_lag_9 91\n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m bg_lag_10 92\n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m bg_lag_11 92\n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m bg_lag_12 94\n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m split and scaling\n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m 148 one hot encoded columns \n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m 23 scaled columns\n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m converting to tensors\n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m Data processing finished\n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m Epoch: 0\n",
      "Result for train_lstm_06101_00000:\n",
      "  date: 2022-07-21_17-14-44\n",
      "  done: false\n",
      "  experiment_id: 509709f5c4f84b7fa7c7f238bc871784\n",
      "  hostname: DESKTOP-LUAPM5T\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 25720\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 47.087101459503174\n",
      "  time_this_iter_s: 47.087101459503174\n",
      "  time_total_s: 47.087101459503174\n",
      "  timestamp: 1658438084\n",
      "  timesteps_since_restore: 0\n",
      "  train_loss: 19090.785156328755\n",
      "  training_iteration: 1\n",
      "  trial_id: '06101_00000'\n",
      "  val_loss: 17120.19303518827\n",
      "  warmup_time: 0.0049839019775390625\n",
      "  \n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m Finished epoch 0 in 0:00:05.014433\n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m C:\\Users\\spenc\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bgpredict-zZmw8Ikr-py3.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1402: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m Finished epoch 1 in 0:00:04.745428\n",
      "\u001b[2m\u001b[36m(func pid=25720)\u001b[0m finished!\n",
      "Result for train_lstm_06101_00000:\n",
      "  date: 2022-07-21_17-14-49\n",
      "  done: true\n",
      "  experiment_id: 509709f5c4f84b7fa7c7f238bc871784\n",
      "  experiment_tag: 0_batch_size=8,dropout=0.0000,epoch=2,hidden_size=2,learning_rate=0.0248,num_lstm_layers=1,window_size=6\n",
      "  hostname: DESKTOP-LUAPM5T\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 25720\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 51.821879863739014\n",
      "  time_this_iter_s: 4.73477840423584\n",
      "  time_total_s: 51.821879863739014\n",
      "  timestamp: 1658438089\n",
      "  timesteps_since_restore: 0\n",
      "  train_loss: 19090.785156328755\n",
      "  training_iteration: 2\n",
      "  trial_id: '06101_00000'\n",
      "  val_loss: 17120.19303518827\n",
      "  warmup_time: 0.0049839019775390625\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 17:14:49,788\tINFO tune.py:737 -- Total run time: 56.52 seconds (56.38 seconds for the tuning loop).\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:30,847 E 21788 29964] (raylet.exe) agent_manager.cc:112: The raylet exited immediately because the Ray agent failed. The raylet fate shares with the agent. This can happen because the Ray agent was unexpectedly killed or failed. See `dashboard_agent.log` for the root cause.\n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:32,884 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:32,884 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:33,845 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:34,855 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:35,855 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:36,867 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:37,881 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:38,891 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:39,893 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:40,903 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:41,911 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:42,917 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:43,932 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:44,946 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:45,955 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:46,961 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:47,963 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:48,965 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:49,977 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:50,992 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:52,003 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:53,013 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:54,015 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:55,018 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:56,021 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:57,027 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:58,030 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "\u001b[2m\u001b[36m(pid=)\u001b[0m [2022-07-21 17:15:59,045 E 6556 20744] (gcs_server.exe) gcs_server.cc:295: Failed to get the resource load: GrpcUnavailable: RPC Error message: failed to connect to all addresses; RPC Error details: \n",
      "2022-07-21 17:15:59,983\tWARNING worker.py:1750 -- The node with node id: bfddd2cd8f6a70bb41481c9d9acd19ce34a068e1788a43d116c1c486 and address: 127.0.0.1 and node name: 127.0.0.1 has been marked dead because the detector has missed too many heartbeats from it. This can happen when a \t(1) raylet crashes unexpectedly (OOM, preempted node, etc.) \n",
      "\t(2) raylet has lagging heartbeats due to slow network or busy workload.\n"
     ]
    }
   ],
   "source": [
    "config= {\n",
    "    'hidden_size': tune.sample_from(lambda spec: 2 * np.random.randint(1,2)) ,\n",
    "    'num_lstm_layers': tune.sample_from(lambda spec: 1 * np.random.randint(1,2)),\n",
    "    'dropout': tune.sample_from(lambda spec: 0.1 * np.random.randint(0,1)),\n",
    "    'learning_rate': tune.sample_from(lambda spec: 10 ** (-10 * np.random.rand())),\n",
    "    'window_size': tune.sample_from(lambda spec: 6 * np.random.randint(1,2)),\n",
    "    'batch_size': tune.sample_from(lambda spec: 8 * np.random.randint(1,2)),\n",
    "    'epoch': tune.sample_from(lambda spec: 2 * np.random.randint(1,2)),\n",
    "    'data_loc': f\"postgresql://postgres:{os.environ.get('db_password')}@{os.environ.get('db_location')}\"\n",
    "}\n",
    "scheduler = ASHAScheduler(\n",
    "    metric=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    max_t=10,\n",
    "    grace_period=1,\n",
    "    reduction_factor=2)\n",
    "\n",
    "reporter = JupyterNotebookReporter(\n",
    "    metric_columns = [\"val_loss\", \"loss\", \"training_iteration\"]\n",
    ")\n",
    "\n",
    "result= tune.run(\n",
    "    partial(train_lstm),\n",
    "    resources_per_trial={\"cpu\":3},\n",
    "    config=config,\n",
    "    num_samples=1,\n",
    "    progress_reporter=reporter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "deea9492-855c-4382-b18b-af29c1f646c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = result.get_best_trial('val_loss', 'min', 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06de1184-79c1-4a37-b9a7-6624e6643bc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_trial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial config: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mbest_trial\u001b[49m\u001b[38;5;241m.\u001b[39mconfig))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial final validation loss: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m      3\u001b[0m     best_trial\u001b[38;5;241m.\u001b[39mlast_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_trial' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Best trial config: {}\".format(best_trial.config))\n",
    "print(\"Best trial final validation loss: {}\".format(\n",
    "    best_trial.last_result[\"val_loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ea298fd8-fa2e-42a9-aeae-5b7318a338b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [113]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m             val_losses\u001b[38;5;241m.\u001b[39mappend((val_loss, iter_idx))\n\u001b[0;32m     33\u001b[0m     iter_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mloss\u001b[49m)    \n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, val_loss)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "# First try with real data\n",
    "losses = []\n",
    "val_losses = []\n",
    "BATCH_SIZE = 8\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "iter_idx = 0 \n",
    "train_X = tensorset.train_X\n",
    "train_y = tensorset.train_y\n",
    "for epoch in range(50):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    for i in range(0, len(train_X_tens)-BATCH_SIZE, BATCH_SIZE):\n",
    "        X = train_X[i:i+BATCH_SIZE]\n",
    "        y = train_y[i:i+BATCH_SIZE]\n",
    "        net.zero_grad()\n",
    "        out_seq = net(X)\n",
    "        break\n",
    "        first_dim, second_dim, _ = out_seq.shape\n",
    "        pred = out_seq.view(first_dim, second_dim)[:, -1]\n",
    "        loss = F.mse_loss(pred, y)\n",
    "        losses.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iter_idx % 50 == 0:\n",
    "            with torch.no_grad():\n",
    "                random_start = np.random.randint(len(val_X_tens)-BATCH_SIZE)\n",
    "                X = val_X_tens[random_start:random_start+BATCH_SIZE] \n",
    "                y = val_y_tens[random_start:random_start+BATCH_SIZE]\n",
    "                out_seq = net(X)\n",
    "                first_dim, second_dim, _ = out_seq.shape\n",
    "                pred = out_seq.view(first_dim, second_dim)[:, -1]\n",
    "                val_loss = F.mse_loss(pred, y)\n",
    "                val_losses.append((val_loss, iter_idx))\n",
    "        iter_idx +=1\n",
    "        \n",
    "    print(\"Loss:\", loss)    \n",
    "    print(\"val_loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8ec0cf5d-0637-4533-a6f3-bda6f9d7decd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "torch.Size([8, 12, 171])\n",
      "torch.Size([8, 12, 1])\n",
      "tensor([211., 214., 214., 206., 196., 187., 167., 157.])\n",
      "tensor([ 0.0354,  0.0035, -0.0315, -0.0402, -0.0322, -0.0221, -0.0262, -0.0298],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(X.shape)\n",
    "print(out_seq.shape)\n",
    "print(y)\n",
    "first_dim, second_dim, _ = out_seq.shape\n",
    "pred = out_seq.view(first_dim, second_dim)[:, -1]\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "747dd4c4-7091-4caf-a90c-9bc79528bfe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15495"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_losses[0:5]\n",
    "len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "ab201803-e8d7-45fc-9d78-806d0583086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_plt = [i.item() for i in losses]\n",
    "val_losses_vals = [i[0].item() for i in val_losses]\n",
    "val_losses_idx = [i[1] for i in val_losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "b7f0af25-a9bb-4ca3-b91c-9c800722c3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 10000.0)"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAD8CAYAAABU4IIeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA1e0lEQVR4nO2dedwd49n4v5dELFESpCkJTWjKG9Qria3e2EtQkrZq11SpKkV5taRpi1petIQUJQghlmiKpJb6qYilrUQWkQ0JQRKJJCSxRMhy//6YOc8zz3lmX87MnHN9P5/zOTP3NtfcM3Nf93rdYoxBURRFUdJig7wFUBRFUeoLVSyKoihKqqhiURRFUVJFFYuiKIqSKqpYFEVRlFRRxaIoiqKkSqBiEZHhIrJERGY43LYUkWdEZI7939F2FxEZKiJzReQ1EenliDPQDj9HRAY63HuLyHQ7zlARkbRvUlEURakdYVos9wD9qtwuAZ41xvQAnrXPAY4Aeti/M4G/gKWIgEuBvYG9gEsrysgO81NHvOprKYqiKCUiULEYY14APqpy7g+MsI9HAAMc7vcai5eBDiKyDXA48Iwx5iNjzHLgGaCf7be5MeZlY63UvNeRlqIoilJC2saM19kYs8g+Xgx0to+7APMd4RbYbn7uC1zcXRGRM7FaQrRv3773zjvvDMDs2bBqFey8M7RvH/OOFEVRCsbq1TBzJmy8MeyyS/L0Jk+evMwY0yl5Sv7EVSxNGGOMiNTELowxZhgwDKBPnz5m0qRJAOy5J0yaBPfeax0riqLUA7NnQ8+e0K2bVcYlRUTeTZ5KMHFnhX1gd2Nh/y+x3RcC2znCdbXd/Ny7urgriqIoJSWuYhkLVGZ2DQTGONx/ZM8O2wdYaXeZPQ0cJiId7UH7w4Cnbb+PRWQfezbYjxxpKYqiKCUksCtMRB4EDgS2FpEFWLO7rgEeFpHTgXeB4+zgTwJHAnOBVcBpAMaYj0TkCuAVO9wfjDGVCQFnY8082wR4yv4piqIoJSVQsRhjTvTwOsQlrAHO8UhnODDcxX0SsGuQHIqiKEo50JX3iqIoSqqoYlEURVFSRRWLoiiKkiqqWBRFUZRUUcWiKIqipIoqFkVRFCVVVLEoiqIoqaKKRVEURUkVVSyKoihKqqhiURRFUVJFFYuiKA3Hm2/C+PF5S1G/JN6PRVEUpWzstJP1b2qyk1TjoS0WRVGUglM2BaiKRVEUpaCI5C1BPFSxKIqiKKmiikVRFEVJFVUsiqIoSqqoYlEURVFSRRWLoiiKkiqqWBRFUZRUUcWiKIqipIoqFkVRFCVVVLEoiqIoqaKKRVEURUkVVSyKoihKqqhiURRFUVJFFYuiKIqSKqpYFEVRlFRRxeLD2rVw4YWwdGnekiiKopQHVSw+/P3vMGQI/OIXeUuiKIpSHupKsaS9y9r69db/2rXppqsoihKFsu0gWRd73pd1lzVFUWrL9OkwcWLeUoSnrGVbXSgWRVGUMHzrW3lL0BjUVVeYoiiKkj+qWBRFUZRUSaRYROQCEZkpIjNE5EER2VhEuovIBBGZKyKjRKSdHXYj+3yu7d/Nkc4g2/0NETk84T25yAnnnpt2qoqiKIobsRWLiHQBzgP6GGN2BdoAJwDXAkOMMd8AlgOn21FOB5bb7kPscIhITzveLkA/4FYRaRNXLi9uvjntFBVFURQ3knaFtQU2EZG2wKbAIuBgYLTtPwIYYB/3t8+x/Q8REbHdHzLGfGGMmQfMBfZKKJeiKIqSE7EVizFmIfAn4D0shbISmAysMMZUVn4sALrYx12A+XbctXb4rZzuLnFaICJnisgkEZm0VJfDK4qiFJIkXWEdsVob3YFtgfZYXVmZYYwZZozpY4zp06lTpywvpSiKosQkSVfYocA8Y8xSY8wa4BFgP6CD3TUG0BVYaB8vBLYDsP23AD50urvESZWDDrLMtCiKoijZkUSxvAfsIyKb2mMlhwCzgOeAY+0wA4Ex9vFY+xzbf5wxxtjuJ9izxroDPYBM1saOHw8/+EEWKSuKoigVYq+8N8ZMEJHRwBRgLTAVGAY8ATwkIlfabnfZUe4C7hORucBHWDPBMMbMFJGHsZTSWuAcY8y6uHIpiqIo+ZLIpIsx5lLg0irnt3GZ1WWMWQ380COdq4CrksiiKIqiFANdea8oiqKkiioWRVEUJVVUsSiKoiip0nCKpWwb5iiKopSNhlMsiqIoZaNsFWJVLIqiKAWlrDtIqmJRFEVRUkUVi6IoipIqqlgURVGUVKkrxfL449C5M6xe7R2mbINgiqIoZaOuFMsVV8CSJfDee3lLoiiK0rjUlWJRFEVR8kcVi6IoipIqqlgURVGUVFHFoihKKVm9GmbMyFsKxY2GUyw6K0xR6oPTToPddoPly/OWRKmm4RSLoij1wQsvWP+rVuUrh9IaVSyKoihKqqhiURRFUVKlLhVLWS2CKoqi1AN1qVgURVGU/FDFEgKdSaYoihKehlMsUZSEdqkpilIEyla5rQvFUq0AVCEoilIPlLUsqwvFoiiKohQHVSw2l18Oe+yRtxSKoijlRxWLzWWXwauvpp/u9Omw//66OlhRlMZBFUvGnH8+vPgivPxy9Lhz5sDDD6cvk6IoSpbUpWLxG/Aq0+yKnj3h+OPzlkJRFCUadalY6oW1a/OWQFEUJTqqWBRFKTVl6oVoFFSxKIpSSsq6xqMRUMWiKIqipIoqlhCsXw/XXw+ffZa3JIqiKMUnkWIRkQ4iMlpEXheR2SKyr4hsKSLPiMgc+7+jHVZEZKiIzBWR10SklyOdgXb4OSIyMOlNpc2YMXDRRTB4cPS42v+rKEqjkbTFchPwD2PMzsDuwGzgEuBZY0wP4Fn7HOAIoIf9OxP4C4CIbAlcCuwN7AVcWlFGRePjj6PHqSgW7Q9WFKVRiK1YRGQLYH/gLgBjzJfGmBVAf2CEHWwEMMA+7g/cayxeBjqIyDbA4cAzxpiPjDHLgWeAfnHlsmRLEjsbiiiToihKFiRpsXQHlgJ3i8hUEblTRNoDnY0xi+wwi4HO9nEXYL4j/gLbzcu9FSJypohMEpFJS5cu9RRMC3FFUZT8SKJY2gK9gL8YY/YAPqO52wsAY4wBUhtlMMYMM8b0Mcb06dSpU1rJKoqiKCmSRLEsABYYYybY56OxFM0HdhcX9v8S238hsJ0jflfbzctdURRFKSGxFYsxZjEwX0R2sp0OAWYBY4HKzK6BwBj7eCzwI3t22D7ASrvL7GngMBHpaA/aH2a7KYqiKJRvdmnbhPHPBe4XkXbA28BpWMrqYRE5HXgXOM4O+yRwJDAXWGWHxRjzkYhcAbxih/uDMeajhHIpiqKUnrKOFydSLMaYV4E+Ll6HuIQ1wDke6QwHhieRpRbEechlq2koiqIkRVfeRyBJ7aGsNQ9FUZSoqGLJGG2xKIrSaNSlYili66CIMilKPaCVt+JRl4pFUZT6RytrxUUVi6IoipIqqlgURVGUVFHFEoFGaXovWgSffpq3FIqilJW6VCxZKYBGWcey7bbQx211ks3y5fDvf8dL+803YeLEeHEVRSkHSVfeKyEpW2vnjTe8/Y44AiZMgDVroG3EN2gn2wBQGRWuoijhqMsWSxROOKF8hX7eTJqUtwSKki1LlgSHUbxpeMUyalS26WvNXFHKxUsvQefOMHp03pKUl7pULEVsgXjJ1LEjXH11bWVZvBhOPRU+/7y211WUMjBlivX/wgv5ylFm6lKxlIkVK2Dw4Npe85JLYOTI7FtriqI0JqpYIlDEllCt+eQTWLcubykURSkyqljqlF69oHv39NM95pjm46iK9uOP05VFKQZr1sBRR8HkyXlLohQFnW4cgbzWsYhET2fqVOt/wQLo2tU9zKJF/mmsWgWbbtrS7cUXo8nhZLvtgsMo5WPmTHjySVi4EF59NW9p0qNIE2+KJEsY6qLFklUX1bhx6aXVty8sXZpeemHxK8x/8xv/xYp77RX9ep9/Dl/5Cjz6aGs/bbE007Mn3H573lIobhSpy7tIskShLhRLVtxyS7rpTZvm7Xf99eleyw/nyzpzpnc4P7/qdCq8+65lDmbQoHiyxWX2bDj//PLU7GbPhrPOylsKRckGVSwF4aKLoscZNQo++yx9WYrKww9bawzcOPJIGDoU3nkneroffghz5yYSTcmRslQmGom6VCxFaj5m9dJPmGBZDTj33GzSD0Ot8/n4460uRTcq+RxHpp12gh494sul5EORvnOlJapYCpBuHCrjFfPn1/a6QYoyiSKdMwc23hjeeit+GnH48EN//9WrayNHWanXFkO93lctqEvFcsMN2bwUt93WvCo3DkVSTFkT516vvhq++AIefDB9eW69Fd5+O3q8qVNhk03gscdSF6nuqJf3u17uI0/qUrEMGWLVfr14/fX4ad98c2u3n/3Mehl///vWfkWs9RTxwxkzBu65J358v3xetQrOOce7G82Pyqy5p56KJ5eiNCJ1qVgA1q/39ttnn3SvNWyY9X/FFemmWwuKovgmTEgnHTelWbnHFSvSuYaiKP7UrWLxI++ZVN/+tmV8Mg3Wrk0nnTj4FeJFbBUpilIbSqtYknRn5UWlsP3Pf9KrPY8fD3fdlU5aYQg7eJ9EsahSUpSWLF5sfRdpLtrOktIqlrxaHUUp9JxyNIKV4qOP9vfPuqUUp8tw/fp462rKRlG6U9OmSPe1apX1/+c/5ytHWEqrWILwK2Bq2edepJezQlGUYxQef9zfPyvFkiS9P/zBMgRa74sv6637s17uI0/qVrGE4YILanu9Rnhh4yrSWijgWiv5556z/hcujB73449rv54nKY3wfivhaGjrxp9+miz+scdGC99IH16RxliyzPf582HDDeFrX0s33f33t2zLFbHFqyhBNGSLxe9j3XBD/7jOQupvf7N+ca9VBLKWb+pU6NcPvvwy2+vkxfbbwzbbxI/v1ZrxM1iqNC5FL08q1K1iiVtLzXP6blyi3muSGnzUF/uMM+Dpp2H69HTTTTt+Xun37p1NukpyylKIF5G6VSxhiFPAFqU7qyhyVJP3QG6ZutEAPvgg2/RrQb0VwEX9tspEQyuWWtMIL2xcxeIsnBohn+oRr+d2zz2WHbisqDfFVg80pGJJ8iIWsdArokzVFKGrqhLGGPjoI+9wXbrA5ZenI5fzummmd/fdySef1IrTToPBg9NPtwzvfaOSWLGISBsRmSoij9vn3UVkgojMFZFRItLOdt/IPp9r+3dzpDHIdn9DRA5PKpOVZhqplIMi32utZPNrKVW7DRsGW23lbb3h/ffhssvc/S6+OPw9ZXXvL7wAP/kJnHdeNukrxaHI37YfabRYzgdmO86vBYYYY74BLAdOt91PB5bb7kPscIhIT+AEYBegH3CriLRJKlSYB1KLh1bEZrrzvrOoTedJmGf65JPW/xtvRE//uuuix0mbSkulHsZnikze77IbRZTJjUSKRUS6AkcBd9rnAhwMjLaDjAAG2Mf97XNs/0Ps8P2Bh4wxXxhj5gFzgb2iyJGWZdwoxNnbo6y1jzhU32uUD6KI+RRW/ocegk8+cfebNAmefz7e9du3h1NOCRf2xhtrqwDLUtiFJcn79+WX1nNudJK2WG4Efg1UjNRvBawwxlQm7S4AutjHXYD5ALb/Sjt8k7tLnBaIyJkiMklEmh7d+PHRhU5jjGXPPbO/Vhg5ik6QnEOHwsyZtZGlmjDPJko+T5sGJ55oTbF2Y8894cADw6fnZNUquP/+cGEvuMDqsqswYUJtbOuV5Z3MkgsusJ6z335QjUBsxSIi3wWWGGMmpyiPL8aYYcaYPsaYPhW3IHtfL7zg7ZfkQ/Ab/M2LZcvg0UfzlSGqIj3/fOjVK30F/N573ts2Z1UAVgrvWm0XHSbPli2z9h869VTr/MsvrXckzfyutxZLEiqtlSKWD7UkSYtlP+AYEXkHeAirC+wmoIOIVEzFdAUqa4sXAtsB2P5bAB863V3ixKZSeBxwQNKU0iOrAq2S7tFHw/e/H7yHe5bEmW7stSp/+nR44IFo163w9a9bq+LLwj//aeXZa68Fh63O23XrYOVK97AVq7iVAu+yy6x35OmnY4saWi6lcYmtWIwxg4wxXY0x3bAG38cZY04GngMqVrQGAmPs47H2Obb/OGOMsd1PsGeNdQd6ABPjypU1RbKBVU1l3CfIekAtCoCoYyxu61i+9S04+eRk140iQ1aEuW6lpfnii9HTP/dc6NABVq8ODlsx49/oNeowFLElVkSZ3MhiHcvFwIUiMhdrDKWyDdVdwFa2+4XAJQDGmJnAw8As4B/AOcaYdRnIlQp518o++QS++CJfGaq5/noYOdLdr9bTjaPIEOUjjfNB1+reK626MIpFCSbvb7weSMW6sTFmPDDePn4bl1ldxpjVwA894l8FXBXn2kVuQWTB5ptDz54tN/yppe0vNy66yPoPO2spLcaOtQxctmvX7Jb2NPM4eZskT4uwkDQsCxbAxhuXpxZdSxo9T+p25X0ZlMb69cFh3Jg1q+V5mHtdvx5OPz37qZBeH1TaH9q4cdC/P/zud9mkH4daV3KysCCxyy7WBmVh2G476NQpOM1GQvPAom4VS1Hws4H1yCPx0436Ai9dCsOHw1FHZffyr10LP7TbpJVrhL1WVFthy5ZZ//PmtXR3i+u1kLAIyigOaSqhF15oOY151iy49FL3sKtXW60URQlCFUtEkhhXrObzz1u7TZpkXSPOqvC8mTMn3sLRLPniC+jWraVbEcZ90ozjh9ckCuesybBdmCecYLVSGoUiVjyKKJMbdatYimLSZcqUaOErtceK2ZG0ifNiLlsGffsWs7YadD/OqcxR790YGDEiXlwntXoXoxjijHO9MWOCw9QD2p2VnNIrFq+XIO+X48EHgxdvpkWYqb1B+TF1Kvz97+5+I0bASy/BkCHpypSENNIPivPXv8ab/hv1OknTzftdz5si1uKLKFMtKb1iqTVhPuLZs+Gkk2DgwJbuWRcASdLv1QuOOSZ9WWq9mVqarYO4az2yLvBrNQtw4ULYYYfW41hh0ly3Ln4L98EH4cwzg8Nl/T2NG9c8wWbNGrjrruaxvbxkKgsNrViyKvQqq52L2nUU17pxlEWOUYkb17nHSprpxqFW3VlpEEbWe++1lMqwYS3dvWScOLF5Lc2gQdZ4zKJFzf6jR7vHq+akk+COO8KFTZMVK1raHpw7t3la/0EHWTbg0qx81TMNrVjKTC33ua9FgRm1QC1qF2hcspY7S4XlTPuss6z/p56y/p01/B+6rmIrDv37WwrEaZ167lzr/1//sv7ffbf2cjkpSxdb6RVLmQqSalnTkr3IeVCR7bjj8pXDjSjKrkgfdJItCLLupgs7WeW555qVjjHw8svZyBOF6dOt/zVrgsO+8kqzVW5jrK2Xly6Nd91KD4cbN97Y8vyJJ7w3qCsSpVcsXhShsK0uANKUybm4Mkq6WXZXLV/efFwtU5RuwTj3U/b9Xipk3Z1Y6wF/N5mMgYMPtloHYG2zvO++4bvKqvnxj5u/h+23txZ5xsH5/npRuZ+99oJdd7WO//Uva+vl005rHQ4sq9dnnQUff9w6vUcesfba8VLITgsbFQYNsv4ff9yarRl3oXWW1K1iCbNneVZjLF5hXn01+vW8uPbaaOFr0RWW1r7mYZSQU6ZZs5otOhfBCGXWdsWyavmGJa19bGbMsP4ra7beeiuePM8/3zyWM39+a8sUFbysaPsR5l4rRl8//bT5vp2tnltvhdtvt1o11VS6DCfH2Hzkhz+0ZmsWzXYg1LFiufvuvCVozc9/nl5azn1moppp8fvoo6Q1dmzL8zgfrhs33RQt/JFHevv5FQxJFU2HDi3P0zB2mTVxp2W/+Wa4NLO41wsvtGZkJcW5+VmFrBb0HnggLF5sHVe+k7AtyiK2QKJSasXy+OPx48ZdnxA0eOfW3M2a99/33o+jmuqXu7o/2W+nweq4/ft7hw2abrxkiX/aYcmydRCUdlCeZ2H/K24+VcsateUddsfUapIomgcftP6HDGnelfO99yy5wmzxvG4d7L57c8E+e3brMDvu2NotrcpIZYuCl14Kn+6JJ0KbNv7pFqmi4kWpFcsdd8TvBli8OF5cr0WEFbz6WZNSvQVztexOk+lBCyRvu635+Be/CL52nHwKWgPSt2/0NJ0UsfvHyaOPWgPUYQl7P87u1GqZ/BTdp5/6pxtkcj9qhSkNperWcq0olDvvDE5v5Upr47Qf/zi6LF4ygXeLorqy5IVIc+upOp9GjQovW5EptWLJiso2rnF4991sCr3KQKcfXteN23edhLfeslpSXvh1rSShVhMZgrj++njxghbgrV3rfY/f+U5rt7Czwty6ibzI2opC3gTJs/HG7u5uLSIvrruu5XkZWiFRUMXigtemVWlT/QJXpjvGieuHs8BJ0tUSNe6iRel1O/nF84vrtgVv1gVZmOmqXlwVa1ciizAVCC/FsjDBZuDO1nT1swhrgj8qzz4bPmwcG3F+fn7PN+rkkaIp1bQotWIpupaPOgvsn//MRAw++yz+CzxlSvFe/i++CL9A8j//aT52e1/uvdf7OnEXbU6d6h/OzUSKU+6o6yGyXsAaNAPRrduzIlOSrSH8cK7o96IythK0VXdSokzacG5REJeil3tQcsWSlKIVmEUkjQ8hbX77W2+/b34zfDrGtLbn5kX1jDe/RW2VtL0ImvW2xx7hZIpDGQqltPjJT6z/oPGlarKc5VbdBVbBr9u4jJResRRROYSVqWIuwo2gFzqudd887Hmlnfb8+d7xKutZ/IjzzlRmKFU46aTwcaPmW1C3VGXjMq/Fh2FIsh4rTHdpFjPiolK0ssGvKyyrLsO8KL1iKRvOAsrNDH3YjyErW2EPPRQ/bi37kJ3pvvdeNtfwW5dTsR2VFlHyya+VNW5cvOvnWeHI4h3x6y4NogiLbP0oggxBlFqxFPGFDkozSk03D26/PX7c6udR9A/ghBP8/YNmaMUly0K8eg+gKC1brxXrRcXvW7vrLmsdSxySPJ+g779oraisKLViqWfCDE56kdVq86jdc1Hwm+jgZw2gqLsaZvUMnBYX4uDVVWVMfBtbbuRdgKa1yV6a34vOCisRZX4wfgva/vQn/7hu9+2XF3mZzQ8b16/AdFvDEzZdt0WKabwzbovkapFPTpPuccYzKgt809wsLK3B7jRbuFnZzypiL0kRKb1iKSJ5vzxRFmqlSRG7vqZNaz4OmnZabcvN736i2EUL6o6qtqoQFrfp6XHfvTyfXd7fS1JqXWkr4ndWTakVSyPXHpw1V2iZF4ce6h0vrE0xN4LyO6sV/ml+SK+95u3nNHUDwVOKnVTbWIsic2VfjzhEnUobhbw3hysC1e9EEsqgENKi1IqliBT1g0qjkLjlFv9w1VN90/qQ0uybnjcvfFy/9SbVMv3sZ95hDzkEzj23+bx6QaEx3jJNnOh/3SgD1Fdc0XycZldYUuLOZHOS5neXZHxMB+8tGlaxZFV70FpeS/KYeedHVs+9urVWbZDw5pubj6OsRt9775bnlf07vPDbq+X3v/eOl2UlIIgJE9K5dhBFNFyqXWEFxJhk3QhZUcZ+7iJTlnxxPne/fT6S3E/Qfjlht5LIupDNosBcty4buSsLTrPGGH9zP2V5z8NQasUC8Otfx49bjy0EL+qpJSWSTHkX7X6SyFQdd/jw5mO/Ma/q61WP2UWVoRZUm0Op7Hfixuefh083igmdeir8s6T0ikUpNllN7c2bJItBa6XY+vXz9qvuqnOzJBDWpEuUe69sehUW5zT0KAs4g6brO0myZuz999OrtIXNxyeeiL/4s1aoYikQF16YTSEaZXZTmgRZ+Q1LmmsSilDjrN5UKyuZ/Dbvqhho9JLBr+CqNph4zz3Nx6+/br3DXoVt9QZvfl17CxbAAQd4+/tRq/U0zo39IJk5mCjXTWsb8KwotWLJa7pxlivQk5ih8Lrup58mW7Ed9378ZkolJe/urKIYTMxq0H3oUO+wO+zQ8rx6CvuMGeGv69zyuLo7Lkr33D/+ET5smvgV8NV5GrSoNsqzLEIFyY9SK5YikneB58WLL+YtQXEo6jPKgrj3GrTNbhYD3tX7vkQZJzn9dH//tFrPQQW68zurbp25GXitV1SxlIhXXslbguj4FWxxu/2KON0Y8m91JEk36riJ3/gNpKO8k+zEWc3ixeHDZvU8qlt21ffnvG7Q1glZ7hmTBrEVi4hsJyLPicgsEZkpIufb7luKyDMiMsf+72i7i4gMFZG5IvKaiPRypDXQDj9HREJuvdR4/OhH+Vw3qxp+3H3hITuZ4n6kZTeJElV+v60KiljQRZFp+XJvvzSV3ciR3l1h228fHL/ILe8kLZa1wP8aY3oC+wDniEhP4BLgWWNMD+BZ+xzgCKCH/TsT+AtYigi4FNgb2Au4tKKMgiiqSZciPvAifuxZmYDx4+mn/Z/PjTeGSyfN/Ew63TgtGarPi74vSRSiyOv3DkTpnguSodp23XnnNR8HteaLnv+xFYsxZpExZop9/AkwG+gC9AdG2MFGAAPs4/7AvcbiZaCDiGwDHA48Y4z5yBizHHgGCGhoF5ekSiXuC3PHHcmumxVZFE4PPBC/Gy0on9wMO7rhN+Oq0SniWqEsibsRXnU+JdkLqWikMsYiIt2APYAJQGdjTGVm+GKgs33cBXBsKssC283L3e06Z4rIJBGZBPGtwialiLWFyy7z989y86K4JJHp3/9OTw4l+hhLEb8BP9KStygKs+j5n1ixiMhmwN+AXxpjPnb6GWMMkFoWGGOGGWP6GGP6QPJaY1FekiJzww3ZWtCNSxEVZdGsAeRV+NRzi6XoBXpRSKRYRGRDLKVyvzGmYlrvA7uLC/u/MnFxIbCdI3pX283LPVOy2gjo5Zfzm7UUt9tp3jz/dJcujSdPEPX0kU6cmM+itazWVGmLJXuSlBVFvB8nSWaFCXAXMNsYc4PDayxQmdk1EBjjcP+RPTtsH2Cl3WX2NHCYiHS0B+0Ps90yJckK9/nzg8OUieoFb1EImsZZrzVXN6JYLXZS1EkocbnvvuzSztvmXdCmbVG4++5kshSZJC2W/YBTgYNF5FX7dyRwDfAdEZkDHGqfAzwJvA3MBe4AzgYwxnwEXAG8Yv/+YLsVlm7dsku7CGsaosT9zneySXfKlPhx8yKuTH/8Y/GUA8RvAQ8ZEv9+5s6NFy+IIrwvQTuYRqEI9+NH27gRjTEvAV6vzyEu4Q1wjkdaw4Hhbn5ZkcRCrtJMUDdaXHr3ziZdKN5zj7J4r1bkVXD16JHPdcNOI3Zbx5JHK6roikVX3jcIeb2I9bQWoogk2e0wq+sWkf79/f2TbL+htKauFcvIkflcN0mTt2wfbJbynsdNGISoEwv9Vk5nSRFnqsWl3sZ9gggyoZIV2mIpIaee6u137cCZHD3l8kyu+/DDmSSbiCK+iEEy3cQvAZCIimX//f39437MT6cwpeTrvMM1XEy1svTLiyR7bxRxDVJcsqwo+t1PlI3AakWSPWRqQV0rFj9epC/HTLmM9qS/SCNNe0JFIKvulqziRjHbHoUgw4th7mc0x3Ix1/EtXgt93UGD/K/ppTwWLYo/GP7ss/HiZc2rr2aTrt+z87vm88/nsxHdLrvU/ppRaFjFshHWQhbjOf8gH/JYx5IUYT2C+9eVyhTP9NbY5s6GRK91+LWUunf3j+s3BXrcOG+/adPgww+9/ZOsn0lSEBfRlM6TT8aPW7Yuw7A0rGIJ4vnn85agHBgD77E9y9g6VtwwpK1Yivgxx20VfvZZ/HQPaTV3syVZFeI335xNuklIUvHKarF1mYk93bjeufLK+HGLuBYlK4yBrhkbSnBTLEXMi6zIq7sxq3STWLUu23O/5prgMF5kZfGiFmiLxYOyvcBB5FU4pdE9V8uusCIW4nmR93OvJVk9d7/xsSBOOSV+3LxRxeJBUQcvi0a79dl3etfTGIsXRZwgkVW6WcV94IH46SYhqzz+qND2R/xpSMXyFT6mDdYczqIVWkUsCPz4eM0msePW2xhLEReh1ht+eXzyydmkmxdFlCksDadYNmI1H7MFG5PdiFuZXwg3GqlLJAwHMJ4LuCE4oA9RlGURWwdJZoUV8bmXMY+LTMMN3m9CS6NAWbRYsnohVq2KH7fML2nRBu/HcxAAQ7gwtTSL2FIt8zvjRiO17PKm4Vos1WShWFasiB/X72N2muvvztv0ZlL8CxWAeusKi0KU9VNFVA5FlCkJKlO6NFyLpZosFMvwGthpfpsdgZbyZ9X9kPcL7rzH3kxiMr3xNqydH0UsxLO6btCmZvX6LrpRb889DRquxVKtSIo2eF9v+H0cK1eGS6PyjA5iHJPYk/O5KQXJ6oc8WmBFVHZFTDcJYWUqouwNp1iqqZViacNawljprbcP55//9PYLu2K58oy6Mw+A3Zie2YSCJKuoi/jsyrx+qSzobMDWqGKpgWLZmqWsZUPOY2iTWxcW8Bj9WxnBjLu9LWS3ZXJWH05Yszm1bFW+/nrNLtWCIiqlrCjithJF7J4r4rMLS8MpljyMTm7PewAMZEST21UMpj9j+QF/axE2q0VRn3ySTbpJCOqnz4Nafcxln26chCD7ZoqFKpaCcgn/xyds1sKt6GMsG/IlR5DAXKoH990XP+6NN6YmRizcnlmSj+7llxMKlACvik0RV96HjTuAR/k5t7ZwK9vgfRHHjFSxFJT/4zdsRsvqUZ6KJUxr6Qp+x5Mcxf6oeeUKbs8oycy7WbO8/ZJsoJRVQfD229mkmxaP8n1u5ZzQ4VWxhKOIMoWlrhWLG0VpsXhd9xtYOzNtzTJX/zas9dz7pF6pziuDhJ5RVkuSLGCdONHbL2gHySIP4rqRx8ZYQRRdeZcNVSwpK5bv8Qg7EMcuuOFoxgbKs5YNGc2x8YQrKUWpDARx113BYbxkf/HFlIWx0Vlh4Yi70yZkdz/vvZdNurWg4RTLBlW1/eoPfUs+ZA1tOYDxnmn0ZhJdWODq9wg/YDq7RZbrDO5kLP35Po8Ghg0Tpp5Iokie4dDC7RIK6U4ief99b78khVOSwtZPpg8+iJ9uWoX4jszlfG5MJ7GMKOKEm7A0nGIJqv3uxUTaso6LudYzjUnsybt83dN/0yp7ZGHo6qGoFPeusLAcSvD+B72YzC7MiCxXGUiybe4zz0SPI6ynPZ/y5pveYV56Kb5MSaYqO3mB/bmRC9iU5FPU8mqBBXWR5kmDKBaH2ZOUulXaxBjnKGoXTlFZbyuQrLvCJtOHGTFamUprruY3fMpX2IxsqtsjRgSH8cK5WHcLrEG6NN6lvBRLkbdEbgjF4uz+Klrh7lX7jirn6dzJRfwxDZEKwwYJWipu3MLZvMruidJIi6K9h2lxKta89s35OGdJWpPVuqnbbosf16mUdudVHmUAbVmTXKicaQjFIhFaLGX94O/kp/yRXweG+wZzOI5RNZAoGt/mXxjEtUuq8kySPpuz+Qu781qiNJISRTmezMhCPqt6IqvvfSNWszOzA8Pd5DB7dx+nMoAx9OVFDJLJerZa0RCKxa/F4vVixasdZ6eU9uXfnMntidOZzm6M4oQUJEqXYxkNwHdo3bFfVmWflJGcWshnVU9UT+apIKxP1HK4g58ym550JLopjV5MASi1sVVVLCkWWlkWgP9mP27nrMTpZLlzZoW9mIBBPGfORaWSr7WY3bUZn7ABBR4VVVLFS7E8xgDW0C5SWidxP8cwBoAD7Vml7WNMDqiHilRDKBbngwqablxN60LGO7zXS1rE6a5efJ136Eoya5Zn2+Y9DsXHtHEE0uoKC2JjPucTNud6/pcOLGc2O7Mr0z3Dd+QjfsBoruNXsa95Kz8P9X6051P+m6mxr6O44/XNHsPfI6d1P6cwhgGe/rdwdqnKgiQ0hGKJ22Lpztusoy0n8oBrWrvxGkcz1tWv+Ljf9zt0Zz7b11gWf/ye0ZE8wbm21eh2fMESOvH9KsOeVhrBz2ZTrKXzp3Ifh/H/2Jk3+C1XeoZ/joMYzQ/5FX9q5XciD/BHLgq8l58TPPI7iKv5B/2YSi+2YEULv81ZSZIu2G1ZSLsYrdj9eIlLuczTP61KwB2cgUFCybgZnzCfrvTlBc8wnVnMYK5skq+W3+zZ/KVm18qbhlAsUQbvnRzBUwAc7xhAbUvzRPrX2J2x9G8qtJJ8TFnUZB5lAG/Sw9XP7YP6L3yMaFVxJYOZwS4t3L4ScybQcYziAnuxmjMPq6cbu+XRE3yXoZwPwNdYTCeWcYPLXvQ/5Y5AOaI+P7+JAA9wMhdxfehrORXfyYzku44a89UM5n/4F9Cs/AB68CYr6cAZ3Nkirf15nn34T6D8bVjLQroygoGBYat5ib5cxuWe/tXv16+5lns5lY1YHSr9i7mGbzGNM7DMGdzPyYFx9mAqXVnIVQz2DDOSU7iS3zWtNauW8zSGs4AuoWRMypZ8yDd5o+m8nlozDaFYNmA93+MROrM4sPBw+t/CL4CWD3xDlwG9yhTLzjQvKT6IcaGvkxUDGEMPmpdPH8tfm46v5WIGcyUGadoTZlaVovBjMFezS5UiuoAhseS8i9Nd3aunGyfJs6+yJDCMW/pZPafqdJ0KYySn8neOcY3nrNh8E2sV4gAeaxHmeQ7kP3w7UIbKu/y9lCw5OFtT1QX2tVzCqYxkFMcHptOWNVzDIHsLaotjHa3QrVnKJHpzPA+xBSsimVDasmowvVrO4ZxOF3zMBtgcwPhQXcbu74/lNp3deIOdA8KWk9Iqlq+xiG1ZGCrsFqzkEX7A3zm61cPbnWlNx8cwpmnPFC8jkM4Pu0Il7KN8r8ltHIfwa67lJO4PJWNc9ibYBnxldotzlslFXM+V/A6oyJ/8pb6cyziYZxnIvb7hdiSarZCwH5xfOC8/ZyurjWM8za32eBrDE9cqDe6LPsMO8jrfvzVs2MotDPvxEnvzsmslyY+tWMb2vFvl2nwfK+jYVCi38ZgA0d/RdezGZnzSNGje1iONpXyV3kzhIU5kMr15i2+4hhPWcx43tdhMrzqv2rCOjnzEDrxFpxCVjwrjOYip7BEYzi0fKm7b4m5KO+h978Y8e0fa4lJaxdKF93mSIz1n8DgHOr/GYsDa2nabqoc5lv5ND2oMAzjOrtXvxStNYQYwhq1s5eH2Ee/JK5zLUL5e9dFdyyXczyl8H+9tISsfd2UlcDVBK5jv5IwW5/14ig1puRJsDe2Yy46eheJ6NvAsCNzYBG8zvs9yqG/cKxnMXHp4Dnj/lDtoxxctZpSFnRVW/UEGmWl5jgN5iiOazr0KaGE9wvpWXU5JSEOxrKUt4N6K9uMl+vIy+0aO9xY78i7dWrh5vTdxxy46sTRS+B1pbZa4L5bNmAE8xk38skXXWPUz3oD1zGBX3uIbLKFzqGtWCvWt+dDVX1jflLdu+RNUETjSXr/i9r53ZjHz2IHrQqxZy5PCKBYR6Scib4jIXBG5JEyc3XnNrjUYLuAGltCJ67mQ3XmVc/lzU7ht7VrU1nzIS/Rtlc48dmCsR9dDhQc5kW1ZyEE818rvBEYxlPM9P6bfchXQ/JJ1Yx6nMhKAuziDJzmiaYzByXX8ik/YnD3see1u7MrMFjWtpziSL9moVWtuR95u6jqpph1f8hNabnCyPe/y1aauPcNxjGJju196Fe095XHSjXeaxg6O4nGOYxSDuRqAX/EntrGfi3PPnP/idVbQgQVs1+R2JsPoxWRP5QtWq6zywW5kD/SO5JQm/z9waas4B/I8+/FvRxrNH/zeTGg6fp9tmcGuvvfalflNNWPneMkv+DPb8y7XcHEL98580GJAenem8W3+FWi7qhNL+SnDWMcGTfnhVVAd3MJOmuFY/tpijKNasfTjKRfjq4arGcR/MYstXMbQ1tqtpmqmxbRwkFZ30Gds2tQ1vSNv0dmuXG5cNcZzFrd5thwsedZzAOOb3lXA9TtyVrae4Ci+Zl+70sXpfK7/w0tczu89r3mgvRfT1ixDWM/WLGVzVrIXEziKJwD4Mfd4xi8Expjcf0Ab4C1gB6AdMA3o6Rent2UNoZS/FWyeuwxhf9dzgXmSfk3n32Vs5DR+yQ2u7s9wSCLZ3qZb0/ECtm3hdzm/M2/yDc+48+mSSX4dzRjzEMe5+r3D9pk9p19yg7mOi1q5/47Lzfa84yrTNHZrOr6Pk1v4/YkLzWMcYx5hQKt4A7k7lEyfs1Gr52LAdGaR2Y1p5kGOb+G+Hy+aV+jtmd7t/NQ8xeGuflfyG/M8fX3l6cmMyPk6hPONAbOSr5g7OL2V/3R2cc2j6rwMus4CtjVr2SCSbH153nyT182yZSY0wKRalOliF+y5IiL7ApcZYw63zwcBGGP+zytOHxEzqUbyKYqiFJUV76ygw9e3CBVWRCYbY/pkLJLdSZs/XaDFFIsFwN7VgUTkTOBM+/QLobS2zrcGj9kB5UDlzxeVP1+KJX+3DlFC75SRFC0oimIJhTFmGDAMQEQm1ULzZkGZZQeVP29U/nwps/wiUpOOnqIM3i8Ex2gtdLXdFEVRlJJRFMXyCtBDRLqLSDvgBAiY8K4oiqIUkkJ0hRlj1orIL4CnsWaIDTfGzAyINix7yTKjzLKDyp83Kn++lFn+msheiFlhiqIoSv1QlK4wRVEUpU5QxaIoiqKkSq6KRUS2E5HnRGSWiMwUkfNt9y1F5BkRmWP/d7TdRUSG2mZfXhORXo60Btrh54jIQId7bxGZbscZKiKp2qYWkTYiMlVEHrfPu4vIBPt6o+zJCIjIRvb5XNu/myONQbb7GyJyuMM9spmbiLJ3EJHRIvK6iMwWkX1LlvcX2O/NDBF5UEQ2LnL+i8hwEVkiIjMcbpnnt9c1UpL/j/b785qIPCoiHRx+kfI1zrNLKr/D739FxIjI1vZ5KfLfdj/XfgYzReQ6h3t++Z+zKZdtgF728VeAN4GewHXAJbb7JcC19vGRwFOAAPsAE2z3LYG37f+O9nFH22+iHVbsuEekfA8XAg8Aj9vnDwMn2Me3AT+3j88GbrOPTwBG2cc9sUzYbAR0xzJt04YYZm5iyD4COMM+bgd0KEveYy2qnQds4sj3Hxc5/4H9gV7ADIdb5vntdY2U5D8MaGsfX+uQP3K+Rn12achvu2+HNXHoXWDrkuX/QcA/gY3s868WIf9TK6TS+AFjgO8AbwDb2G7bAG/Yx7cDJzrCv2H7nwjc7nC/3XbbBnjd4d4iXArydgWeBQ4GHrdfqGU0f2j7Ak/bx08D+9rHbe1wAgwCBjnSfNqO1xTXdm8RLgXZt8AqmKXKvSx5X7HWsKWdn48Dhxc9/4FutCwYMs9vr2ukIX+V3/eA+93yKyhf43w7ackPjAZ2B96hWbGUIv+xlMGhLuFyzf/CjLHYzas9gAlAZ2NMxeToYmiyZ+1m+qVLgPsCF/e0uBH4NTSZrd0KWGGMqZibdV6vSUbbf6UdPuo9pUV3YClwt1hdeXeKSHtKkvfGmIXAn4D3gEVY+TmZ8uR/hVrkt9c10uYnYG+7Gl3+ON9OYkSkP7DQGDOtyqss+f9NoK/dRfW8iOwZU/5U878QikVENgP+BvzSGNPCNrex1GTh5kSLyHeBJcaYyXnLEpO2WM3qvxhj9gA+w2qmN1HUvAew+6n7YynIbYH2QL9chUpILfI7q2uIyGBgLWS8s12KiMimwG/Ax4Z9ymSQ/22xWu37AL8CHq6M7eRJ7opFRDbEUir3G2MqO2J9ICLb2P7bQNOGI16mX/zcu7q4p8F+wDEi8g7wEFZ32E1ABxGpLDx1Xq9JRtt/C+DDGPeUFguABcaYysYjo7EUTRnyHuBQYJ4xZqkxZg3wCNYzKUv+V6hFfntdIxVE5MfAd4GT7YIzjvwfEv3ZJWVHrIrJNPs77gpMEZGvxZA/r/xfADxiLCZi9Z5sHUP+dPM/bl9fGj+sfr17gRur3P9Iy8Gu6+zjo2g5oDbRdt8Sa7ygo/2bB2xp+1UPqB2ZwX0cSPPg/V9pOQB2tn18Di0HwB62j3eh5SDb21gDbG3t4+40D7LtkrLcLwI72ceX2fleirzHsn49E9jUTn8EcG7R85/WfeSZ57fXNVKSvx8wC+hUFS5yvkZ9dmnIX+X3Ds1jLGXJ/7OAP9jH38TqspK88z/VAjZGJv0PVrPwNeBV+3ckVv/ds8AcrBkPlQcnwC1YsxqmA30caf0EmGv/TnO498Eyr/8WcDMxB/0C7uNAmhXLDvYLNtd+UJXZGhvb53Nt/x0c8Qfb8r2BY+aUnRdv2n6DM5D7v4FJdv4/Zn8opcl74HLgdfsa99kfUWHzH3gQazxoDVZN8/Ra5LfXNVKSfy5WYfaq/bstbr7GeXZJ5a/yf4dmxVKW/G8HjLSvOwU4uAj5ryZdFEVRlFTJfYxFURRFqS9UsSiKoiipoopFURRFSRVVLIqiKEqqqGJRFEVRUkUVi6IoipIqqlgURVGUVPn/96wfE8J1kHgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot([i[0].item() for i in val_losses])\n",
    "plt.plot(losses_plt, color='blue')\n",
    "plt.plot(val_losses_idx, val_losses_vals, color='red')\n",
    "plt.xlim(20000, 160000)\n",
    "plt.ylim(0,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "816205cb-36f5-4fc4-9dbf-6c62a87d4da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117.23619236927281"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(val_losses_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "cfc159a0-c457-4adf-8283-4d072b5f5bb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [407]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 2\u001b[0m     pred \u001b[38;5;241m=\u001b[39m [net(i)\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m val_X_tens[\u001b[38;5;241m1000\u001b[39m:\u001b[38;5;241m5000\u001b[39m]]\n",
      "Input \u001b[1;32mIn [407]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 2\u001b[0m     pred \u001b[38;5;241m=\u001b[39m [\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m val_X_tens[\u001b[38;5;241m1000\u001b[39m:\u001b[38;5;241m5000\u001b[39m]]\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out_seq = net(val_X_tens)\n",
    "    first_dim, second_dim, _ = out_seq.shape\n",
    "    pred = out_seq.view(first_dim, second_dim)[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "98873866-b20e-4459-aeb6-dae706d8d368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123.05413202953339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38.67697523647435"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.mean(pred))\n",
    "np.std(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "f3c125ad-c875-447c-835a-a9a9029feb19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x153342e1000>"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_plt = [i.item() for i in val_y_tens[1000:5000]]\n",
    "plt.scatter(y_plt, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "7b011a0a-c3a0-4981-a1f5-3d75ff20f5f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [387]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(preds)\n\u001b[0;32m      3\u001b[0m test[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bgpredict-zZmw8Ikr-py3.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1129\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1128\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [383]\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m----> 9\u001b[0m         lstm_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#         print(f\"here: {lstm_out}, {lstm_out.shape}\")\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#         print(f\"{lstm_out[:,-1,:]}\")\u001b[39;00m\n\u001b[0;32m     12\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(lstm_out[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bgpredict-zZmw8Ikr-py3.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1129\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1128\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bgpredict-zZmw8Ikr-py3.10\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:731\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    730\u001b[0m     batch_sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 731\u001b[0m     is_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m    732\u001b[0m     batch_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_batched:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "preds = net(test[:100])\n",
    "print(preds)\n",
    "test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec9d249-b24c-4816-9612-1daef12d8e23",
   "metadata": {},
   "source": [
    "### Padding\n",
    "Initial tests showed padding to perform very poorly. Keeping code here in case it's needed in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "210b05e2-cae3-4531-b646-080c82cd40f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Padder:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.max_length = None\n",
    "        self.padding_array = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Determine Max Length\n",
    "        lengths = []\n",
    "        for i in X:\n",
    "            lengths.append(len(i))\n",
    "        min_l = min(lengths)\n",
    "        self.max_length = max(lengths)\n",
    "        median_l = np.median(lengths)\n",
    "        mean_l = np.mean(lengths)\n",
    "        print(f\"Padding up to length {self.max_length}\")\n",
    "        print(f\"median length = {median_l}, mean_length = {mean_l}, min_length = {min_l}\")\n",
    "        \n",
    "        # Create padding array\n",
    "        feature_width=X[0].shape[1]\n",
    "        self.padding_array = np.expand_dims(np.zeros(feature_width), axis=0)\n",
    "        \n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Prepend padding to X\n",
    "        for idx, i in enumerate(X):\n",
    "            # Number of arrays to prepend to the existing data\n",
    "            pad_length = self.max_length - len(i)\n",
    "            pads = [self.padding_array for _ in range(pad_length)]\n",
    "            pads.append(i)\n",
    "            X[idx] = np.concatenate(pads)\n",
    "\n",
    "        return X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b05d851f-0354-4708-90a4-f11c6f4649d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding up to length 40\n",
      "median length = 23.0, mean_length = 24.035937815465374, min_length = 1\n"
     ]
    }
   ],
   "source": [
    "padder = Padder()\n",
    "padder.fit(train_X)\n",
    "train_X_padded = padder.transform(train_X)\n",
    "val_X_padded = padder.transform(val_X)\n",
    "test_X_padded = padder.transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad11d711-f757-42b6-ab5a-3f6c400e148b",
   "metadata": {},
   "source": [
    "# Toy Example/Practice Stuff below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "b07df404-f652-4e52-8bb4-cc489c922f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8421, -0.0994, -1.0581,  0.4492, -0.0721])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.9606,  1.0944,  1.7780,  1.3661,  1.5622,  0.3268, -0.9777, -1.0041,\n",
       "           0.5847, -2.3832, -1.1196,  0.7594,  1.7240, -1.2549, -1.0124,  0.2177,\n",
       "          -1.0469,  0.8911,  0.8690, -1.2307,  0.2678,  0.2080,  0.8018, -2.6957,\n",
       "           0.5934]]),\n",
       " tensor([[-0.2270, -0.7460,  0.0676, -1.2601, -0.3686, -2.3264,  0.5884,  1.2743,\n",
       "          -0.3886,  1.1344,  1.3895, -0.6844,  1.4866,  0.4065, -0.1946, -0.1110,\n",
       "           1.9018,  0.3833, -0.0099,  0.8776, -0.1576,  1.5975, -1.4378, -0.5403,\n",
       "          -0.7007]])]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate fake data\n",
    "inputs = [torch.randn(1,25) for _ in range(5)]\n",
    "out = torch.randn(5)\n",
    "print(out)\n",
    "inputs[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "d44dd63c-ddd9-424d-8306-f402f343c989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 1., 39.,  0., ...,  0.,  1.,  0.],\n",
       "        [ 1., 49.,  0., ...,  0.,  1.,  0.],\n",
       "        [ 2.,  4.,  0., ...,  0.,  1.,  0.]]),\n",
       " array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 1., 49.,  0., ...,  0.,  1.,  0.],\n",
       "        [ 2.,  4.,  0., ...,  0.,  1.,  0.],\n",
       "        [ 2.,  9.,  0., ...,  0.,  1.,  0.]]),\n",
       " array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 2.,  4.,  0., ...,  0.,  1.,  0.],\n",
       "        [ 2.,  9.,  0., ...,  0.,  1.,  0.],\n",
       "        [ 2., 24.,  0., ...,  0.,  1.,  0.]]),\n",
       " array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 2.,  9.,  0., ...,  0.,  1.,  0.],\n",
       "        [ 2., 24.,  0., ...,  0.,  1.,  0.],\n",
       "        [ 2., 29.,  0., ...,  0.,  1.,  0.]]),\n",
       " array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 2., 24.,  0., ...,  0.,  1.,  0.],\n",
       "        [ 2., 29.,  0., ...,  0.,  1.,  0.],\n",
       "        [ 2., 39.,  0., ...,  0.,  1.,  0.]])]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87f9094e-30a8-46c0-a653-e8efade3bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(input_size=10, hidden_size=20, num_layers=2)\n",
    "# five batches of size 3 with 10 elements in each row\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "c0 = torch.randn(2, 3, 20)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69bae2c6-e219-4493-b235-dc6f97d0f629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The': 0, 'dog': 1, 'ate': 2, 'the': 3, 'apple': 4, 'Everybody': 5, 'read': 6, 'that': 7, 'book': 8}\n"
     ]
    }
   ],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "training_data = [\n",
    "    # Tags are: DET - determiner; NN - noun; V - verb\n",
    "    # For example, the word \"The\" is a determiner\n",
    "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]\n",
    "word_to_ix = {}\n",
    "# For each words-list (sentence) and tags-list in each tuple of training_data\n",
    "for sent, tags in training_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:  # word has not been assigned an index yet\n",
    "            word_to_ix[word] = len(word_to_ix)  # Assign each word with a unique index\n",
    "print(word_to_ix)\n",
    "tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2}  # Assign each tag with a unique index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9241d661-fda4-45f9-bc89-79544799739a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_sequence(training_data[0][0], word_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f822df-378f-4758-bc13-3ac883620378",
   "metadata": {},
   "source": [
    "## Using someone elses example (Not Functional)\n",
    "First, we'll try to replicate the example used [here](https://towardsdatascience.com/pytorch-lstms-for-time-series-data-cd16190929d7). \n",
    "\n",
    "After working with this a bit, it turns out this example was not even close to complete, and I'm not going to spend a ton of effort debugging it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26835aca-7a1a-4f01-97ed-dcd2f4930555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data\n",
    "N = 100 # number of samples\n",
    "L = 1000 # length of each sample (number of values for each sine wave)\n",
    "T = 20 # width of the wave\n",
    "x = np.empty((N,L), np.float32) # instantiate empty array\n",
    "x[:] = np.arange(L) + np.random.randint(-4*T, 4*T, N).reshape(N,1)\n",
    "y = np.sin(x/1.0/T).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34c3043f-a2f6-4e50-bb06-0aecf8bf376a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f7df5d3-752f-4f08-96b2-c136be618125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM Class\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hidden_layers=64):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_layers = hidden_layers\n",
    "        # lstm1, lstm2, linear are all layers in the network\n",
    "        self.lstm1 = nn.LSTMCell(1, self.hidden_layers)\n",
    "        self.lstm2 = nn.LSTMCell(self.hidden_layers, self.hidden_layers)\n",
    "        self.linear = nn.Linear(self.hidden_layers, 1)\n",
    "        \n",
    "    def forward(self, y, future_preds=0):\n",
    "        outputs, n_samples = [], y.size(0)\n",
    "        h_t = torch.zeros(n_samples, self.hidden_layers, dtype=torch.float32)\n",
    "        c_t = torch.zeros(n_samples, self.hidden_layers, dtype=torch.float32)\n",
    "        h_t2 = torch.zeros(n_samples, self.hidden_layers, dtype=torch.float32)\n",
    "        c_t2 = torch.zeros(n_samples, self.hidden_layers, dtype=torch.float32)\n",
    "        \n",
    "        for time_step in y.split(1, dim=1):\n",
    "            # N, 1\n",
    "            h_t, c_t = self.lstm1(input_t, (h_t, c_t)) # initial hidden and cell states\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2)) # new hidden and cell states\n",
    "            output = self.linear(h_t2) # output from the last FC layer\n",
    "            outputs.append(output)\n",
    "            \n",
    "        for i in range(future_preds):\n",
    "            # this only generates future predictions if we pass in future_preds>0\n",
    "            # mirrors the code above, using last output/prediction as input\n",
    "            h_t, c_t = self.lstm1(output, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            output = self.linear(h_t2)\n",
    "            outputs.append(output)\n",
    "        # transform list to tensor    \n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e9a3589-6137-4a03-a3e5-f36ce31be608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([97, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.from_numpy(y[3:, :-1])\n",
    "b = a.split(1, dim=1)\n",
    "b[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34d45de9-c4d4-4322-ab19-1377cd8df035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABWnElEQVR4nO29ebRk2VXe+dsxv3jzlPNUQ6oGDVUlJUJCGAupJCS6W6VuZJDc2AUWq9qroT3Q2EjNWmBjWIYeLEybBqo1IGQWAmQDZSFQS6UZTZVyVUk1Z1Zl5Ty8eYoX8+k/7r0R8V5GvLjDOedG5rvfWrnyvRs34u24+5yz9/72PvuIUooECRIkSLB7kYpbgAQJEiRIEC8SQ5AgQYIEuxyJIUiQIEGCXY7EECRIkCDBLkdiCBIkSJBglyMTtwBhMDMzo44dOxa3GAkSJEhwQ+E73/nOvFJqdvv1G9IQHDt2jJMnT8YtRoIECRLcUBCRs92uJ9RQggQJEuxyJIYgQYIECXY5EkOQIEGCBLsciSFIkCBBgl2OxBAkSJAgwS6HFkMgIh8VkWsi8lSP10VEfltETovId0XktR2vPSgip9x/D+qQJ0GCBAkS+IeuiOAPgHfs8Po7gePuv4eA3wUQkSngV4DvB14P/IqITGqSKUGCBAkS+IAWQ6CU+gqwuMMtDwB/qBx8E5gQkf3AjwCfU0otKqWWgM+xs0HRivOLJT76tTMsrFds/UlfqDWa/NG3zvLE+eW4RbkOX3r+Gn/x+EUGrX35uYUSH/vbMyyXqnGLsgWVeoNPfPMs37uwErco1+GLz13jkScvDZwuz8xv8LG/PcPKZi1uUbagXGvwiW+8zNOXBk+XUWFrQ9lB4HzH7xfca72uXwcReQgnmuDIkSORBWo0Fe//+GO8cHWdv3n6Cn/6P70x8mfqwv/96Cl++wunyWdSfOEX3szBiaG4RQLgsZcX+amPPQbAZq3B+14fXQ86UG80efBj3+bM/AZfeO4an3j/98ctUgv/7nMv8PtffoliLs1X/+UPMz2Sj1skAL5+ep6f/gNHl7V6kx973aGYJXJQrTf5Bx/5FheWNvnaqXk+8lPfF7dILfzm3zzHx/72ZUYLGb76L3+YiWIubpG04YZJFiulHlZKnVBKnZidvW6HdGB8/tmrvHB1nfuOTPDtM4s8f2VNg5TRUa41+PDXznDv4QlqjSZ/8u1zcYvUwh9+4ywTxSy3zQ7z8a+/PDCe5F8/dYUz8xvcd2SCr56a58z8RtwiAbBRqfOxv32ZVx8cp1Rt8MnHzvd/kyX84TfOMjOS49h0kT/8xstxi9PCI09e4sLSJvcenuDR565xYakUt0gArGzW+MQ3zvKaQ+Oslev82ckLcYukFbYMwUXgcMfvh9xrva4bx6PPXmWskOH3fvJ1pAQ+/d1LNv5sX3z9xXlK1QY//7ZXcOLYFJ99+mrcIgGOgfrCs1d556v28VM/cIznrqzx4tx63GIBjlGfGcnxH/7+axGBTz85GLr86qk5qvUm/9uP3sWJo5P8zVNX4hYJcAzUF5+/xn/z6v385BuO8uSFFc4tDMaC++izV9k3VuC333sfAJ/53uWYJXLwpeevUW8q/tW7XslrDo3zN08Phi51wZYheAT4h2710BuAFaXUZeCzwNtFZNJNEr/dvWYUSim+8sI8f+f4LHvHCrz60ATfemmnFIc9fOWFeYayab7/1inuv2sPz19d49paOW6x+N7FFTaqDd5y515+8LgTkX3rTPzPTCnFV0/N80PHZzk4McSd+8b49svxywXwlVPzjOYznDg2yZtun+HpSysDwXs/cX6ZSr3JW+7ay99p6XIhZqkcuvZrp+f5u6+Y5ch0kdv3jPDNAZqXU8M57j00wZtun+HJ88tsVOpxi6UNuspH/xj4BnCHiFwQkfeLyD8WkX/s3vIZ4CXgNPD/Av8zgFJqEfg3wGPuv191rxnF3FqFK6tlXnfUKVB63ZFJvntxmVqjafpP98WTF5Z59aFx8pk09x1x5Pvu+fiTU4+fWwLgviMTHJsuMjOS57EBMATnFzdZ3Khy4tgUAK87OsHj55ZpNOOnrZ48v8w9hyfIplO88bZpmgq+czb+Z+bp8t7DExzfM8L4UJbHBsB4vjS3zlq5zutvcXT52iMTPH5uaSAoyCcvLHPf4QlSKeENt05TbyoeP7cct1jaoKtq6H1Kqf1KqaxS6pBS6iNKqd9TSv2e+7pSSv2sUuo2pdSrlVInO977UaXU7e6/j+mQpx+edfMBd+0fA+C1Ryco15qx5wlqjSbPXFrlNQfHAXjVgXHSKRmI6qEnzi9zeGqImZE8IsJ9RyZ46tJq3GLxlFvB8Wr3mb32yCTrlXrstFW51uD5K2u85pAj1ysPOGPt2cvx56KeOL/MbbPDjA9lSaWEew5P8NTFwdHlq1xd3ndkkqVSjbMx01beeHrNoQmgPdaevRz/M9OFGyZZrBOeAu92DcGd+5z/4zYEL81tUKk3ebW7eAzl0tw+OzIQA+6Fq+vc5T4ngDv2jnJmfoNKvRGjVPDUxRUyKeEV+0aAwdHlC1fXqDdVa9EYLWQ5PDXEMwOiy7sPjLd+v3PfKKfn1qnHHBE/dXGVQjbFbbPDLbnAeZZx4rnLqygFrzrojK2p4Rx7x/IDMS91YdcaggPjBcaLWQCOThfJpoUXrsVtCBwv9rbZkda12/eMcDpm77bWaHJ2YYPb9rTlumPfKI2m4sVr8VbonLq2zi0zw+QzaQBunR0mJc71OOFVLnU+s7v2jcW+eJRrDc4vlbh1Zrh17Y69o1TrTV6O2fM+fW2d22ZHyKSdZen4XscQxK3Ll1xd3t6hyzv3jQ2EUdeFXWkInru8xp37295tNp3i1pkRTl8djAF3rGOS3rZnhPOLJcq1+Dzv84slag21ZfF4xd7B8NZent/Y8rwK2TRHp4c5FbNcL81tIAJHpoqta7fvGeHcQinW/MXZhRJKOQbTwx0D4nm/vLBVlyP5DAcnhmKX68z8Btm0bNnPc/ueEV5e2BiI/IUO7DpDoJTi5YWNVvjp4fY9I62FOC6cmd9gz2iekXx7n9/te0ZoKmeSxIWX5q73bo9OOwvcucX4vMhmU3F2scQtM1t1edvscEvmuHBmfoODE0MUsunWtSNTRepNxaXlzdjkerFL1HlkAHRZazS5sLTJLdNbdXnrIOhyboMjU8VWpALO+C/XmlxbG6yuBGGx6wzB3FqFSr25xVMDODQ1xMWlTZoxemtn5jeuW9S8iRFnwqy1eMy0F49CNs3esTznY1w8Lq+WqdabLaPk4dBkkQtLpVi9tW66HIQF16MfOyOCsUKWyWI2VrkuLG3SaKotEQE4xjPuTWWOLke2XPPWjzifmU7sOkNw3h1Uh7Ybgski1Ua8Fv7M/Aa3zm4dcAcnnXD04lJ8XuSZ+Q2mh3OtnIqHw5PFWCfCy24Et92LPDxVZKPaYKkUT82+UsrR5bZF7egAGPWX5jbYP16gmNvaXebwVDFWo+7p8lgXo75UqrEeU81+o6k4s7CxxXDCYOhSJ3afIVh0FtTDk1sH3GF3wT0fk/exslljcaN63USYLGYp5tJciNEQXFja5PA2wwmOVxTn4nGmS04FOnQZk2wLG1XWK/Xr5No3ViCXTnF2MT6qo5cu4zYEPXU5Fa8ur7hR57FtzsbBiSFSAudipGx1YtcZAs+DPTS5tZGbNzniGnAeb3xwm1wiwqHJoVjD40vLmxyYKFx3/fBUsUXPxIHziyVymRT7xrbK5ukyLuPZ0uW2ZoHplKPLOBfcSyubHBi/XpdHpopcXN6MLZF9brHEcC7N9PDWRm6HJgdDl9vHfy6TYv/4EGcTaujGxPnFEntG81uSeNCetF7EYBuXV5y/u3/8+k6jByeGYpsISil38bheriNTRZSCizElPy+vlNk/XiCVki3XD8Uc3V1adlqCHOjSNfbIdDE2OqHRVFxZKXeV6/BkkVpDcWU1nnYmV1bK7J8YQmSrLuOO7tqG4PpndnQ6XmpUJ3afIVgqdQ2NC9k0e0bzsXne7cXjem/t0GQxtsV2qVSjXGt2XzxijqKurJSviwbA2bw1UczGJlfbqF8v2/7xIa6sxLPYzq1VqDdVD1061+JqPnd5tdz1eU0N5yjm0rEZ9cuurgZNl7qx6wxBL48IcCmY+CKCdErYM9rNEAyxslljtWw/+dkrNIb25IjLi7y8utl1goLzzOKMVPKZFFPbaA5w8gQLG9VYdmRf7EFZQVuXcTU4vLzcXZceNRpXscSVlTKj+Qyjhex1r+0bz3NtrTIQfa2iYlcZAqWc0HffWPfDQfaNF+KbCCtl9o7mSW+jOaAdlsZRf75TaDw76jzHqzF4RU2X5tjXhbICZ8G9uhpPBdgld1HbTnNAx4Ibg2ytSKWLUd/rRlZxeLi1RpO59UpPXe4dK3A1pmq+S8ubXZ8XOGOs0VTMD9gJh2GwqwzBarlOudZsDfrt2DNaiGWCAlxedjjSbvDkjWfx8ELj62UrZNNMFrNcjcF4LmxUqTVUz4hgz1iBa3FFKivlrs8LYK8r79UYZNvJqI/kMxRz6ViM57W1CkrRNYkNzvgfRF16hutmoId2lSHwJt+eHoZg71iBtUo9lj7jl1d60xx7XM87jj0Ol1Y2yaVT11VzeNg7VuDKin25vMm3r9fiMepQMHFUNF3u40VC28DaxKXlMiP5DGNdaA4RcaMo+3JdcSOVnroccyiYODZ7Xl7pXjEHbV3GRY3qxK40BN0SjOAMOLC/4CqlWhUw3bDHlSuOSTq3WmF2NH9dZY6HvWPx0GkezdGtmgnaupyzHLY3moqra5WeuvTGXiy6XKu0nIpu2DOWjylS6R11gjPGGk3FwkbVplhU603m16vsG+sV3cU3L3VjlxkCZ1HY2yNHsDemSbparlOpN7smigGKuQyj+QxzMUQEc+sVZnZYPPaO5WMJjT0vzJuM2xGXLpdKVRpN1VOXY0MZCtlULM+sny73jRVi8W77OWie8bKtS4/739NjvZgZzpNJSUINeRCRd4jI8yJyWkQ+0OX1D4nIE+6/F0RkueO1Rsdrj+iQpxe8gdQrR7A3Js/bG3Azo93pF4jPW5tbqzA7svPiMb9esd7Lfn6tQkpgeri7bN7ktc0tt3TZ45l5FEwcC+78WqWV4O+GveNOjsx2j6a5tQq5TIqxoUzX1z0q13bk2U+XqZSwZzR/U1BD3Z98AIhIGvgd4G3ABeAxEXlEKfWMd49S6p933P+/APd1fMSmUureqHL4wdXVMuND2es2k3nYE1NSdt719GdHuhsocBPZMUQE8+sV7jsy0fP1PWMFmgonhO5Bh5jA3HqVqeFc1yor6IwI7D4zL2qbGelt1J3kZzzR3Q/tYNT3jhaoNposl2pM9sgJmZJr1j35rqtcMemybQh2ctDiKzDRCR0RweuB00qpl5RSVeCTwAM73P8+4I81/N3AuLpa7kkLAYzmMwxl0zFEBA73uVNEsDeGiKDRVCxuVHeMCOIM23t5agBTxRyZlMQY3fWWbWYkz/yG3cWjXGuwVq7vHBF4C65lz3thvcr0DoutN/6s63LNnZc7jLOZkXxSPuriIHC+4/cL7rXrICJHgVuAL3RcLojISRH5poi8u9cfEZGH3PtOzs3NhRL07xyf5cdee6jn6yLCHrdCwSb6haDgeh5rdsP2hY0KTdVnUXNfW7ScyJtfr+y4eKRSwuxo3r4X6WPxmB7JsbBu/3nBzt6t9zzjkG2n55VzN+dZj+7cZ7aT8ZwZyVlPYptAZGooIN4LfEop1bmt8qhS6qKI3Ap8QUS+p5R6cfsblVIPAw8DnDhxItRq+JNvONr3nunhXCyLWkpgsrhDCDqap1pvsrJZY2KH+7TK5S5qO0UEMy5Hb9srWlivcmQHygqchW3Rsuc9v+7y3YXeU2tmJM/KZo1qvUkuY6dew6Os+i1qgPWFbX69wisPjO14z0wMupxbqzCSz/SkksEbY1WaTdWzsu5GgI5ReBE43PH7IfdaN7yXbbSQUuqi+/9LwJfYmj+wjqlh+6He/HqFqeHuu4o9TMcwSf14RFMxLh47eZHgJJJtG/V+fDe0dblUsidbi37cKVJxjfqCxfGvlHKpoZ11ORWTg7ZTBAXOM2s0FSub8Zx9oQs6DMFjwHERuUVEcjiL/XXVPyJyJzAJfKPj2qSI5N2fZ4A3Ac9sf69NzIzYH3Bza9W+A25q2D4FM7/Wn7IazqXJZ1JW5SpV65SqDR+GINdaAG1hfr2/LqdjiKL8RATjQ1nSKbFKDa1s1qg3lS+jHgdltdPzgk4H7cbOE0Q2BEqpOvBzwGeBZ4E/VUo9LSK/KiLv6rj1vcAn1VaS+y7gpIg8CXwR+I3OaqM44HkeNrl4XwNu2D5/6yciEBHrCTOPstopR+C9bt+o949UPENh00h5+ulVbgtOXmWymLO6qPnJXYCbV7EeEVR96DLfuvdGhpYcgVLqM8Bntl375W2//6su7/s68GodMujC9EieelOxulm/7mhGU5hfr1x3vu12eJ0sbS5sc2sVhrJphvM7DxPbyU+v4man3AU4UdRmrUGpWr/uaEZTmF+v8JqD4zve49EgNimYubUKE8Vs35zEzIjdKMr7W/11mWNls0at0SSbtpNXmV+v8MZbp3e8J64Eu27sqp3FfuB53rbK+5RSvrjItiGw6631i1TAeWZWvUgflBXYj6KabrntTmXAEM/iMb++88ZAD7ajqFak0k+X7utLlmSr1p39FH4jgl1PDd1s8CaprcmwUW1QrjX7LriFbJqRfMZusnitv4ECx/NejMGL9EMNgb1Ettdeot/iMZrPkEunrO4l8JNcB4+Lj8Oo98ur2NWlt7D3M+qTxRwi7e9xoyIxBNsw1fIi7SjWr3cL9isnFjf6V3OASydYzKu0vcjBiqL8VOaAk1exTactbFRbFV47YWrYvlxpNzexE2xHd372g4BzDvVU0Rn/NzISQ7ANrRI6y55Ht9OstsO2IVgqVZn0kSeZHslRrTdZt9S+e2G9wlghQz7Tu74b7CfyPF32M1DgyGbT817a8KfLmZEca5U65ZqdE9Sc0ulc3xp829U5rYjAhy4do55EBDcVpix7HksbtS1/dydMW/TWlFIslWp9PTXorD+35K1t9K/mAPsJdk+Xvp6ZxSqYplvnPuVLLrtlyvPr1Z5nXXRiyvIYWy45uvSzeTOO0lbdSAzBNuQyKUYLGXuLh7upyM/iMWUxKVuqNqjWm76aj9neVLZcqjLhw7st5tIUsilr3loQXU4P563xyqvlGk3ld1GzazyXS1Vfz2tiKEtKLBr1ILq8CdpMJIagC2zWxbc9j/4L29SIvT0O7Yngg06wvCN1acNfpCIijrdmcVEDf7qcHrHHK3uL5+SwH7nsbnZbKtV8yZVKiVVHaKlUQ8TZZNcPN0PjucQQdIFNLn6pVCWTEkb61OqD463VGoo1C1x8oNA4lojAX78lm0nZpVLNjUJ2zl2AYyyq9SabVfNc/FIpAGXllU9bo2AC6NIiBbO0UWWskN2x7YuHiWKWtXLd+pkcOpEYgi6wycUvlZwmcjv1pvHgcfE2SjU9Q+gnd+EtMLZ65zi5C3+b/WwbdT+LLbSf2fKmedmWA9AcLbks6FIpxXKpxoQPrxs8atSeLv2MfaAl/43cbygxBF0wNZyzt6j5rOYAu1x8EGqokE2Ry6RYKZmfCOVag81aw/fBKVNFe7pcLtV80ULQXjy8BLNJtKghH4ZgtJAhJXYWtbVKnXpT+TaeNudlEF16Y3E5MQQ3F8aLWZY3a9a4eN8TwfO8LRiCINSQiDBZzLbeYxJBcirg6tKCXBBMlxMWPW/v+/vl4seHslYW3OWNYLqcKGatOBsQTJdeHsGGLk0hMQRdMDHk1MWXa+Y5v0CeR9Ge5+F5kX7D9okhO96aR6VMDPkN23OsV+rULPC3gSIC9z4bugyShwJnnFkx6pv+IxVwnpktBy3MvLQR3ZlCYgi6wBsANha2QJ5H0Z7nsVyqMlbIkPHZ4MubpKbRrtX3G7bb42/D5AhsjTG/eShwxpmd5+U/UgHHqDeaysrGxXD5nsQQ3FSYbC24ZhXbSpb5nAijeXv87VLAA8wnillrBsr5e0HDdrPPzDucxK+BmrA0xsArt/XfSXfCFjUUVJeWnlml3qBUbfh+ZjYdNFNIDEEXjA/ZqegoVRtUG03fnofH31pZPAJ4RGCPTgjsRbrfYcWwLlc3ayifm7bAaSJYyKasLB5LpWogo25NlwGS2NCmKU3LFiQ/BjBWyJBOibVclAkkhqALPG/NdGLK87r8bP33MFHMWeOVg3iRXlLWNH8bZMcn2KvOacnl00CBTeMZXJc2krKeUfezaQs6q3PMGs8gpdPgFEvYSrCbghZDICLvEJHnReS0iHygy+s/JSJzIvKE++9nOl57UEROuf8e1CFPVNhK5AWtgAHciMCCF+lz966HiaEc1UaTTcPNypZLVQrZlK9NW2BPl0sBvUjAXTws0XwBdblmIcHu5aH8bNpy5LITESy1KKsAdJrF6jQTiHxsk4ikgd8B3gZcAB4TkUe6HDn5J0qpn9v23ingV4ATgAK+4753KapcUeBVpJi28G0vMhgXb2ODVHA6oT1JTZ4GFnhRs1SmGWTTlofJYs44ZeXkoQLqsiPB7qe5X1gEzUPZ4uJb5bZBqVELmwNNQUdE8HrgtFLqJaVUFfgk8IDP9/4I8Dml1KK7+H8OeIcGmSJhyD2Q3XR43N7oEyyRN2jJMrBXabVcqvmmEsBegr3dxiHYMzMdETilsyoYNWSpLt6rZvILW4n/oPQjuAn2XV4+ehA43/H7BffadvyYiHxXRD4lIocDvhcReUhETorIybm5OQ1i7wwboV7QpJR3ry2PKKhcYD6v4rdbpQdbCfZW4jNQdGc+RxBGl+02E+ZlC2Kg8pk0xVx6ICnbiWIuaTHhA/8FOKaUeg2O1//xoB+glHpYKXVCKXVidnZWu4DbMTFkPtRrcZEBPNzxoSyr5TqNprmkbCuJHZCyct5r3lsLkpAFOwl2b9PWqM9NW9AuuTWZYA9XkGDP8w5i1MFOgn1po8pQ1l/zQA9OdLe7qaGLwOGO3w+511pQSi0opbw+rR8GXuf3vXHBRmuC5VKN0QCbtqCjosngwtbaVRzAI7LVRG3ZbdIXBDb2OCy5O1H9btoCh0aqG94gFaQFtQdbObIgu3c92CiWCNLU0MNkMUup2qBSN1cs8e0zi/yjP3iM84sl7Z+twxA8BhwXkVtEJAe8F3ik8wYR2d/x67uAZ92fPwu8XUQmRWQSeLt7LXbY4OLDeEQTFhJmHr3jt40D2OFvlVIsB9i05cGGLoO0U/YwYYGC8RyG8QC6nLCwG7vWcI42DTP+zVNDwZLrYIcafXlhgy88d83IZ0c2BEqpOvBzOAv4s8CfKqWeFpFfFZF3ubf9ExF5WkSeBP4J8FPuexeBf4NjTB4DftW9FjtsVAGE8TwmWpvdzA241bK7eASQzcYGKY8SC754mNdlkHbKHmyUQ662DEGwBLvpDVLLIZLrYCu683cCXidsUKOekQkyL/1CS52fUuozwGe2Xfvljp8/CHywx3s/CnxUhxw6YSNZvLpZYyzg4uENApOex+qmQ1WMFYIND9P87UqIxCdgJVm8slnjwEQh0HtsbJBaLTu6HA2gSxsbpLzFfDywLs0nZVc2a+wbD6hLC2XKK5s10gHzUH6R7CzugfFilkq9SdngBqnVzWClkNDhRRpcPFY2a6QE390qPZjeIOV958DPzMIJUqvlGmOFcLo0+cxWN2vkM/434HkwTcF4i3nQKMprd24ywb5argceY+MWdLm86WzAC5KH8ovEEPRAi4IxOUnLwSMCG7yyJ1fQAWd6g5QXqQSdpJ63ZtKTXAkR3bV5ZbNGPejzAmeBNhl1roSgrMAxUKYT7KubwY16K7ozGkWF06UfJIagB0xvkFLK6VYZdMB5dI1pXjmoXGCeTvNyF2NDwSIV020mmu7CFNwQWIgIQjgb4BhPk9RQW5chc2SGnlm51qBSb4aQy3wrkzCRil8khqAHTNdSl2tNag0VWLGZdIrRQsa4dxvKiyzmzCbLQnqRpiua1sp1lAouVzadophLtxK6JrC6WQ+c6wHz5dNh81DjhsunwxqoYi5NJiWGdRnOqPtBYgh6wPM8TFEdYb1bMF85sVquh5JrfCjrtmM2w996kywwF2+4FXVLlyEW3LFCtvV+Ewhr1D1dmoK3kIf2vA0ZqfYYC6ZLEWFsyKwuE0MQA0xHBGG9W/B2PQ8eNTQ2lKHaaFKpm0nKrpadqoliLmDi03Ar6rCLGjj6NxndhaWGxoeyrFXM7WBf3axRzKXJBthMCW2jboq2WgmZh/Le473fBMIUJPhFYgh6wJs8pix8WO8WzDcrC+tFet/FlCfpyRU0ie3pcs2wLkM9s6FMiyYxgai6NPbMQi5q46bnZUhqCJwowtTYV0o5NF+ISN0PEkPQA8O5NCnB2CSN4kWODWVZG1AvEgzytyH5bu89Xk29brSpoXALrqlFzVk8wkZ3nlE3N/7DLGree0zJFc2om4vuKvUm1UYziQhswzTn19q9G9JbMyVXpd6gXGuGW3AteGthDFQmnWI4lzY2SVs0X4gdnyapoY1qg6YKl4eyYdTDjP2hrJuUHcBI3eh6EcFA+UFiCHaAyUnq1WiHqugYyrK6WTeSlA1bqw8dnrdBby3sRBgzmPwMWwEDZuWKkodqR1GDRQ21HDTDzyxUtFLIDiSD4AeJIdgBjmJNTQR38QjJK5tKykbhSE17kWH2XXgwGUV5O7GHQ5zMNuYmZZsGkrJRvdvOz9CNsNEdtFuxm8BquU4hmyKfCVaQAGar5qJUpvlBYgh2wNhQxtyAC1k1Ae2JbWLB1bJ4GPMiwyfLTCZlvUUt5fPs3U6MFTIoBWsGdsquRvAijRv1CLtkTSZlw+ZUwLCDthnecfSDxBDsAJMRQSTv1qC3FimJbbhqKMokNUnzRVs8zOsybOITzBj1ZlOxVgmX+AezSdmwVVZgdvxHySn6QWIIdsC44WRxFI/I+wzd8CKg8RCedy6TYihrJikbduu/B9PUUFhdmvS8W/RjCCM1nEuTTomRKGq96uzEHkRdRqWswIwuVyJE6n6QGIIdYNrzCE9zmCvti0INgTkKJkruwnufyXxPaF0WzHnebWoouGwi4lAwBuRqF0oM1hgDL1KPOC8N6jJIO/Eg0GIIROQdIvK8iJwWkQ90ef3nReQZ9/D6R0XkaMdrDRF5wv33yPb3xomxQoZyrWnk+Lmw5XNgdlNN1OoEU95alMoc732mkrI6IgKT1NBoBNrKTKSiwagbK9MMPy+9sWkqugvTTtwvIhsCEUkDvwO8E7gbeJ+I3L3ttseBE+7h9Z8C/veO1zaVUve6/97FAKG9I9WMhxulAgbMcZG5CAPOFJ0Whe8GR5dKObSEbkRNMDqfYWaMeaeNhYGpHFk78Rk+iqoaOitEBzVkKlI3lR8APRHB64HTSqmXlFJV4JPAA503KKW+qJTyTlz+Js4h9QMPkwtumP71HkYN7pR1du+GH3AD60V6lVYGWnNE0aVJOiGKXGCuTDMq320qwd5sqsh7VcBU7s5cwznQYwgOAuc7fr/gXuuF9wN/3fF7QUROisg3ReTdvd4kIg+5952cm5uLJLBftCkYvZMhbP96D4VsmnwmZax8NEyi2INT2jeIuQszk9RLYoddPEZyGVJiqhQ4/BgDx2M3adQHrVhio1p3dmJHjNSNORuG8gOg6cxivxCRnwROAH+34/JRpdRFEbkV+IKIfE8p9eL29yqlHgYeBjhx4oS5c+o64IWuuieD178+imJNJT+jeh6m+Nv2Brzw+whAf9i+Vo6Wu0ilhFFTFEw52uJhjhqKFt21q3P06jLKrmJoV82ZypFNjwQ73zkIdEQEF4HDHb8fcq9tgYjcD/wS8C6lVMW7rpS66P7/EvAl4D4NMmmBKWpIR02wqYqOKHw3tHdX6k7KRo4IDFXn6Nj6b2qPQ1Re2VS+Z7VcR4TQh7Cbiu6itFfxYLJqbtBzBI8Bx0XkFhHJAe8FtlT/iMh9wO/jGIFrHdcnRSTv/jwDvAl4RoNMWmBqwOlaPEwMuCgVMOAsuE3lhNk6EfYQdg+mqnOi5i6c95rZwR71IJOxoayRqrnVzRoj+Uyondhg3kGL6giZMuqm9hCABkOglKoDPwd8FngW+FOl1NMi8qsi4lUB/R/ACPBn28pE7wJOisiTwBeB31BKDY4haA04/Yta5+eHgUkKJkrP8xYFo3lhi0xZGWrLEbWaCQxSMOWIiX9DTQSjRiqmxpgOB81E+bRSKvK87Actn6yU+gzwmW3Xfrnj5/t7vO/rwKt1yGAChWyKXFp/UlYPNZTl5fkNXSIB7f71UekEcBJmByeGdIkWOVIZLWQQMWCgNBj18aEsp6+t6xIJgHqjyXol2mHnnRHx7Ghel2iRT9oyFhHoMOpDWa6tlXWJBDjtxBtNNdgRwc0Mp+Wtfi4+alLKe6/uRa1UbVCPOOBMcfFhD6XxkEoJI3n9zcqiJrHBjBe5pkMuQy0Touyqh3bVnG5d6mjjYIIaMn0WASSGoC9MhO1aklIFZ8DpbHmrh+82x99GraM2seBqiQiKBhYPDXy3Oc87GmUFZqjRVhI7UqWV/mSxjnnZD4kh6INRA5tqovSv9zA2lKXRVJSq+hJ5OgyUqb0XOnZWjhlIsEdNYoOZViY6chfGdKmhAsbIghsxiQ3tSiudVXPt9iqJIYgNXjmkTqyWa4wWwvWv92Ci35CO0NhkUjayF2mgj33U3AWYaWWio3+9qX00UauZwFBEoEmXuluZ6KCS+yExBH1gYvHQMuAMVDRF6VbpYaRVaaLvmemqmjBDJ0Rf1Ey0L27TCdFyF6BXl7VGk41qQ4NRN0On6ZAL9D6zJEcwADCxeERNlkFnCZ3+iCDKgEunhNG83gR7SVPVhInoTktEYGDx0KHLVlJWoy7XIpx30QlTutThbHifpQs68j39kBiCPvAOpNablI1W1geGPA9NA0534zkdixp4yWLdvHK0aiYwtHhoOshEdyuTqO0lPJiomovSgtqDiVYm3meZOosAEkPQFybOIdXCdxvIEegacLqTsrqqJsaGMqxX6tQb+nSphxrSv0FqZbNGJiUUc9H61+tOyuo6acur5tNdNaeNGtIcqQ/n0mRCnG/uF4kh6AMTrQl0bBc3setzxa2aiDrgdPdB0lU14b1fZ1J2UKkhz0CJhC9IAP39hvQZ9Sz1pmJT45kEOnRpKt9jMj8AiSHoCxNVMKvlGuNFPRGBbrl0tLrVzd9qo4Y0R1HeTmxd0Z1eaig6ZQX6aT4dJcqgv1ii1mhSqja0GCgw4DgmhiBe6F48KvUG5Voz8iTNplMUc+mBHHDmeOXoCUbn8/QsHusVp3991EWtkE2T05yU1eHdgv4NlbpKIXV73u2cSjS5RvP6W5nooKz6ITEEfaCbgtFR3+1B907ZqCdaedCdlNWWxNZ8oImO9hIedEdRuk600n1Kmb6CBDO6jBqpp7yqOd3RncE9BJAYgr7QHRHoojlAf+/zqN0qPYwPZbUmZXUmscGEF6nDeGrWpaa2xd4pZbqSsqubNdJakth6KRitujRAjSbUUMzQnSzWWROsOyJY1VBHDW1vTVdSVlsSW7Mu9Rp13dFdtGMqPYwVnFYmG5pamXiJz6hJ7EF20HQ3nkuooQGA54XqUqyOnucedC8eOnY8g/4SOl1JbO3UkEZdmqGG9FBWAGvaFlxNSWzdlK3Gxm46HbSo55v7RWII+iCfSVPIprTxpO3t4nomg66J0Ggq1ip6qKExzUlZXUnskbxzULwuubRGBBpbJpRrDar1plZd6qTTdDlBoFMufY3ddFK2a5Xo55v7gRZDICLvEJHnReS0iHygy+t5EfkT9/Vvicixjtc+6F5/XkR+RIc8uqGzcqKVYNTExeuaCOtlfUls3RUdujhS53wJfd6aTl3q3CmrszeN7jJNXTXxuqvmBpUastFnCDQYAhFJA78DvBO4G3ifiNy97bb3A0tKqduBDwG/6b73bpwzjl8JvAP4f9zPGyjo3FSjk04YG8qypqnlre4kNuit6NDFker0vD1djmihOvTtlNVKc7RaJmg06hp1qZN+zKaFQja6b6xTLp1U8k7QERG8HjitlHpJKVUFPgk8sO2eB4CPuz9/CnirONmiB4BPKqUqSqkzwGn38wYKOjfVrG7WyEXsX+9B50Hx7SS2nkUN9FZ06Cqfc8J2fZN0tJAhHaGduIdxd6esjvMlVjRt2ur8DH2OkL5SSJ0UjJcfi5rEBme9KFUb1DRUzdloOAd6DMFB4HzH7xfca13vcQ+7XwGmfb4XABF5SEROisjJubk5DWL7x1gho88QaKwA0HmIt+7EJ+hNFusKjbVGBFp1qe+Z6doc5XyGZi5e4zPTSsFojDp1Vhq29x3dADkCG1BKPayUOqGUOjE7O2v1bzsUjL4NZToSxaDX89ZJDRVzadIp0TJJG03FmmZqSKcudYXsOrl4ndTQqMbqnFYSW+Mz00nBjOqSS6eDVr5BcgTAReBwx++H3Gtd7xGRDDAOLPh8b+zQ63no2xyis3JC5+IhItoqmnQmscGALjVVc+hMsOs06pl0iuFcWm+konH868zd6dKlTgdN9zPrBR2G4DHguIjcIiI5nOTvI9vueQR40P35PcAXlJMVewR4r1tVdAtwHPi2Bpm0QmsiT2OyzEgIqmsyaJqkuj0ipzpnsEohQW9S1vsMXf3rdRlPnXko8PZe6Ktm0ulseJ8ZFaubNURgJML55n4Q+dOVUnUR+Tngs0Aa+KhS6mkR+VXgpFLqEeAjwCdE5DSwiGMscO/7U+AZoA78rFJKX19ZTRgbyrhJ2QYj+WiPbGWzxpHpYT1ytTZuRZ8MK5s1UkLk7+dB1wapFY18NzhyeQfF5zPREvZrGg4Y8qBzE95quU4hm4r8/TzoapmworHPFrTbnTebKtL53+B1ax3ESL3OaD4T+fv1g5bZpZT6DPCZbdd+uePnMvD3erz314Ff1yGHKXSG7VEXSicpNXh0gq7+9R50JWXb3q3mpOxmndnRaAulzlJIrdRQSW//el1cvO6a+M6D4qPqQXdBAmjK92xGb1nvBzdMsjhO6OL8Wv3rNQ04nQfF66SsQN8GKe3UkCbPu95oulv/9Rh1nUnZ1XJNm+EEfWWaukshW553KZou20lsvQ6aDuO5slljNJ8YgoGArmZlm7UG9abStqilU8KoptJWXf3rPejajd1KfGryinR53usVfbuKQXNSVvOJVrr20eg6V8KDLqOus/MoQCGbIpvWUzVn43QySAyBL+haPHT2M/GgLWwv6+15ri3BqD2JrSeK0nmuhAddz8yIUdc0xrzP0wFdB8XrrJgDr2pOjyPklJsnhmAgoCsp2x5w+hZcXYk8/dRQlkq9STnimbKrZSeJPaypaqIdtmvSpcZmYPp0qS8PBY5c65V65FYmK5s18pp21YM+B21Fs7MB+g70WdG4q34nJIbAB/QNOP3bxcc18bf6vUg9ZxJ4ORVdVRO6dsrqrNX3oM/z1nuQybiblF2r6NGlLmijhgxs2hrVWHJrur0EJIbAF3QlZU1sDhnUxUNXywSdlTmgL99jRJca6uKbTaXtXAkPY7rGv2a+28sbDaQuC9F7WtUaTUrVRkINDQrS3jmkA+h56OCVK/UG5VpTe4IRNORVNOcudB0Ur5tXdj4reuJ/o1qnqTTnoTRGxDrpl5Gce1C8LkOgNVKP7qDZ2lUMiSHwDR2VE7oTn6CHVzYil6aSW93eLeipaDL1zKIbKP1NyvRV5+g9aat1UHzkfI+eM7E7oWVeGtBlLySGwCd0hO26N0eB43lsRGx5a8K7HdfUeEs3NQR66uJ1J7FBT1LWq6nXHXWCnuoc3UZ9vKjDQdObxAbP2ahHaktjIg/VC4kh8IlxDX3sV8s1hlxqQhd0JGVNHH6hjYs3kCzTEbY7ZxHoS2JDR1I2gi5N9K/XV3JrwKjriO4058fA0WW10aRSj+CgGaCseiExBD6hI2w3UQrmJcyieEUmBpyu6hydB5l40NH+wgxlFf1kN1NJbIgml1JKe74H9OTITNTqe98z0rw0EKn3QmIIfEIXF2/CI3I+O8qA8060GqykbLXeZLOmv2pCR0M8E4uajqSsCTpBR1J2o9qg0VRmIgItlWn6nQ2I9swSamgAocXzMMCR6lw8dHseHk8aFqY8Ih3VOSZoDh1txXXv3gUnKRs1ijJ1CLuufI8Jasj77LAw0YmgFxJD4BNjBScpW4+YlB3MAWeGi4yaVzEll+NFRkvkmchd6KjO8Z7ZiG4PN2ITQVNGXQ81ZKIgQQNlW66RTQuFrPllOjEEPuHRAJESeZq3/oMeLn61XCOnuWoCoh9OYyo0Hh/K0oh4ULyR3IWG3jlOEjtDWnP/+qhJWa+ayYTx3HS7h4aFEZpPQzdZb7e/rtbwOyExBD6ho82E0YggCgVjIPEJ0RcPU3XUuug0U9RQ5DFmgEqIysW381BmPO+1kLJ5reFNOBsQPbqzQQtBREMgIlMi8jkROeX+P9nlnntF5Bsi8rSIfFdEfqLjtT8QkTMi8oT7794o8phE1LDd2/qvW7Fey9uoXKTuSAW8iCCagQITlFU0XXpJbN1GfTiXISXReWUTVSZRKRjdLag9RDWeparTGl73GPP2CkU5K2FFc2+mnRA1IvgA8KhS6jjwqPv7dpSAf6iUeiXwDuC3RGSi4/V/oZS61/33RER5jCFqmaa39V+35yEikSep7oZzHsYjJmVNtOSA6CdIrRmSK5USRqNGUZs1rdVfHqImZU00XIQOOi2kw2Eqd5HLpBjKRjtfwqGsbgxD8ADwcffnjwPv3n6DUuoFpdQp9+dLwDVgNuLftY6oi4fJ7eLRKRgznocnV9ikrLFqpog13iZ1GdnzHlhqyNtVP1gRgcnKnPGI3QjWDJS19kJUQ7BXKXXZ/fkKsHenm0Xk9UAOeLHj8q+7lNGHRCS/w3sfEpGTInJybm4uotjB0fY8wg44c7sEo/ZBMsVFjg1lqTcVmyHPJFjdrJNLp8hr3IkN0cs0zeoyYnWOITphfChLKUIrk9XNOiP5DJm0Xl1Grdc3cUaIh6hlyqYi9W7oqxUR+byIPNXl3wOd9ynH7evp+onIfuATwE8rpbzR9EHgTuD7gCngF3u9Xyn1sFLqhFLqxOys/YAiuudhbpdgVC7eHDUUNYpydmLrrpqIWmllKlIBDdU5phL/UY1n2Yx3G3XXs1GjHiGKcnZi28sR9NWMUur+Xq+JyFUR2a+Uuuwu9Nd63DcG/BXwS0qpb3Z8thdNVETkY8AvBJLeIoayaTIpiTARzIag5xdLod5raus/bF1w940XAr/fVLJsNGIrBxP9fDyMFbK8NL8e6r31RpONasNYpALOOJ4e6Rm494QpXUZ20Azle7zPvLpWDvXecq1JraE/id0LUeO0R4AH3Z8fBP5y+w0ikgP+HPhDpdSntr223/1fcPILT0WUxxiiJmVN7ayEaIdglAxt/Qc9dJoJuTLpFCP58MnP9nnFg5UjWDOch4JodJoJQ5DPpMilU6F12drfYCiKihp1Dgw11Ae/AbxNRE4B97u/IyInROTD7j0/DvwQ8FNdykT/SES+B3wPmAF+LaI8RhGFgmnTCWbC45WQSVmTAy46f2uuamKsEJ6/NelFRqnOManL6J63/j5b4B4UH8VBM3AWgQfHQYtazWQnWRzpryilFoC3drl+EvgZ9+f/CPzHHu9/S5S/bxtRPG9PsSN5M16kl5QtBuyPb7LDYdR6/dXNGkemijpFaiHKrufVzRqZlDCkeSc2bN0pG7RduVHKSoMu79o/qlOkFpwEe3i5irk0Wc1JbHDG/1q5RrOpArcrt9mCGpKdxYEQyfMwVDUB0UpbTZbPtXbwhtxUs2qwfC5KN1mP7zax9b91Dm+Iha1NWZmM7sLSaeYqYKIk2E0eDj82lKWpYL0a/JndaNTQrkIkL9JQ1QREC9tNDrh2Ujb4RDBdNRGlm6ZDcxgyUBHoNKM0X4R8T6OpWKuYoYYgWltxE2cReIiiS5tnEUBiCAIhSltlU8kyiDZJTW39B8imUxRz6VATYbPWoNZQxiapE7YPsi5DRHcGeeWhbJpsWkIZz/WyuUjF+9wouTtTPHy75DZERGDgyNGdkBiCAPA8jzBJWZPe7XgECsZ0CBq2CsZ0L/axCC2yTdIJUaI7k7yyiISmYEyPsaiJf5NjDELq0mASuxsSQxAAY0OZ0OeQrhg4ncxDlIZ4JpPYEH5TjemqifGhLGuVOo0QB8WvmvQiI1JDmZRQzOlPYkN4z7udxDany0F00CLNS4NJ7G5IDEEARPXWTC5qEFYuc0lsCF8OabpqwvvcMO2LV8sGeeUI1Tneomaqf33YBLvJXfXe54ZtZWKq8y5Ea2Vis70EJIYgECIlfwz2Fh+NcAiG6QEXNiIwTieENJ5KKVZKg0oNmVvUIDwFY7KsFcI/s2ZTGTk+1kOUcy9MUlbdkBiCAAjrrdUaTdYqdSaLORNikUmnGM6lQw84kzxk6ByB4aqJsH2QNmsNqo0mE4Z0GWWnrHGjHrJqzuRmSghf2rpWrqMUxnQ5ms8gEjLxb+AEvJ2QGIIACOt5eBHERNHcJB0POUlNVsBAeDph2U18TxhMMEJwo96Sy5AunZ2y4TZImW5SFrZqzntmphyhsFVzS6UqYE6XqZS4rUwSauimQthzSJctGIKwm93MU0MZ1ip1mgGTskulGiJmeWUIbtRNGyiIoMuSWUMQNim7vOkcwm4qiR22as7GvAy7x8Hm6WSQGIJAiLp4GA/bQ3rek4YNlAqxu3KlVGWskNV+CLuHsIm85U3Hixw3+cxClmkub5rWZbiqueVSlfGhnLkkdsjqnGU3IhgfMhOpQPgc2XKpaiyC6obEEARA2GSxN+BMKtYZcMHD9qVS1RhHCuHbTCxv1oxHUBB88VhpRQRmn1lQXTabiuVS1axcIc9xMO1shKVsV6xE6sGr5qp1p524yahzOxJDEADeOaSh6YQBC0HLtQaVetOoXJ7xWw5oCJZKNaMTYTiXJp0KvlPWoxMmhw3TaQHlWqs4Z2Lb0KXHrfvFcsmsUfeKHQaR5gtTLOFFnSaf2XYkhiAgJorZ1mLgFy0u0qgXGTwp1UqWGZTLG8xBF48Vw5GKd75EUAO1bCEiCLV4tBKf5uTyvPrAz2yzZpR+8c6XGEjKNgQ11Io6E2pocDFRzLUmnV+slKqImN0u7u2UrQc4U7ZdzWHSiwxnCExTQ+Aa9cCGoEouk6KQNTd1wpwvYUOX4y1DEDQiqBqVC0LqcrPKqMHNlEAoZ2PJAoOwHZGegIhMicjnROSU+/9kj/saHYfSPNJx/RYR+ZaInBaRP3FPMxtoTBazLUX5xbJbmRO0J3kQtCiYAF6RtzibTHxOhKSGlg1TQ+A8s1A0h8Hdu+CMsXpTsV7xzy2bLoWETmoohC4NL2phdLlSqhkd+wCTwzk2aw3KAXY928gpbkdUU/gB4FGl1HHgUff3bthUSt3r/ntXx/XfBD6klLodWALeH1Ee44iyeJjERAhvbaXlRRqkhoaC0wkNb8en4YkQzqhXrSxqEOyZtROfJqmh4DmCcq3BZq1hnOaYCKFLp1DC1rz0L5sNymo7ohqCB4CPuz9/HOfcYV9wzyl+C+CdYxzo/XEhXAhqY1EL7q3ZCEEz6RSj+UygxcOpVTdLc0A4ms8x6nZ0ubjhX7alDS/fY+6ZDeXS5DOpQBVgtg5YmQyjy82aca87jPH0ksWTwzdORLBXKXXZ/fkKsLfHfQUROSki3xSRd7vXpoFlpZQX/14ADvb6QyLykPsZJ+fm5iKKHR7egAuyQWqlVDUeEUy5g2YpwOLRGnCmvbXhbKBJamOjD3gRQUA6wULuwqtICrZ42FlwJwI+M9O7ij1MFrOBxj641JClSD3IM1sqOV1khw1twOuGvtlLEfk8sK/LS7/U+YtSSolIr9XxqFLqoojcCnzBPbB+JYigSqmHgYcBTpw4EbzfrCZMFJ3j59bKdd/84vJmjWMzw8blgoCLR6lGPpOiYODs3U44dFrw3IVpz3uimKNca1KuNXw/g+VSjdccMh+peH/LL5ZLTs8ok4lPCK7LZQu5C+fzc6yWnWIJv8/ARkGC56AF1eVE0dwGvG7oawiUUvf3ek1ErorIfqXUZRHZD1zr8RkX3f9fEpEvAfcB/wmYEJGMGxUcAi6G+A5W0Rnq+TUESxvmdwmGoYZs7V6cKOYCJbFXLFBWsFWX+8eHfL3HyREMIJ1gTZfhojvz1FB7U9n0SL7v/TY24DlyBdflioU81HZEdR8eAR50f34Q+MvtN4jIpIjk3Z9ngDcBzyinNu6LwHt2ev+gIWjY7iQ+zfWv91DMpcmlU4FDUBsDbmIo6OJhviYeOkpbN/wZqXKtQbnWNK7L8aEsIsFoPlu6dKjRwYsIPD7dryO0XjW/AQ86IvVA+R7zxSXbEdUQ/AbwNhE5Bdzv/o6InBCRD7v33AWcFJEncRb+31BKPeO+9ovAz4vIaZycwUciymMcQcN2G51HwdkgNVHMsuxzUQPH87azeATjb23s+IROXfqTzUZLAoB0ytnsFii626xZ2YAUtDrHVo4gsC4tVebkM2mKufRA6rITkXY4KaUWgLd2uX4S+Bn3568Dr+7x/peA10eRwTa8xcmv520r8QnBS1uXSlVumx0xKJGDoPyt6c6jHtrRnb9Jait3AcF1uVyqcnSqaFAiB16llVLKF4dtuvOoh/bGRX+6bLd9GUxdvvLAmEGJrkeyszgggnLxyzYXj+GAFR0WkmXQnqR+G6mZ7jzqISh/a6NnlIegZcqmG7t5CLrZzXTn0bZcAXVpsZ/P5PBg6rITiSEIiDGXv/UbgraSZdYiAn8Dzjty0Q6dEHSSWspdBNyEZ9MQTBVzvvcR2NqAB8GpUVuLWlBdLlmiHyFYRGBrA952JIYgINr8bTAu0saAC7JBqlT1jlwczElq43kF5W9XLCWxvb/h93nZ2oAHwXeK22gvATCSz5BJiX9dWmiv4mGimPOdI7OVh9qOxBCEQJDKiXYPGBtcpBOC+mlW1mqnbClSAf/VOSulqhXvFoJ5a0uWEowQrP2FjT5DHtrVOf6jO5OdRz04xRL+jWc7IrAzLwcxD9WJxBCEQBD+dnGjSkrshaD1pmLNB3/reSg2Jmlw/tZe+VxQXeYzKSs7PoM0K1u20GfIQ9BusssW+vl4cKrT/OtyNJ8hlzG/BE4Wc6yWazR8dCOw0UW2GxJDEAJBvMgFdzOZyc6jHloUjI/JsGIxIvDCb7/94hfXq60dmaYRSJfrVaaH7ez4DLJTvF2QYIfmcP5mf10qpVjYcJ6ZDQSdl9MjtuRyjmv1M/6XLVJWnUgMQQgE8SIX1ivWBpy3eC76mAxeItJGY6uxQoZ0SnxN0kq9wVqlzoylZxYsIqgwZUuXAei0xQ07tfrQpsX8PLONaoNqvWnNqAfWpS0DFYBOs6nLTiSGIASCeB6LG/a82yDVOQvrFQAr3pqIMOFzg5RnoKaG+7cJ0IGgXqQtuYJskPJ0OTNqXrZsgG6yrTHmo+WDDgSN7mzr0k/CeHHDe2aJIRh4TBazlKoNKvX+/K0TGtuaCP6rcxa83IWtpOxwjsV1P4uHc4/NsH1l0x9/u7BeZcaaF+l/g9SCxdwFuLr0sagtbNjV5cSw/2KJhY2qtaizFd350OX8epXRQoZ8xl7nUUgMQSi0Qj1fYbtNLtK/XPMuD29605aH6eEcC663sxO8xcPWJJ0czvnmb21Gd60zCXwY9fn1CjMjeWvdKmdGfOrSM+qWntlUMUe10WSjurODppRiyWqk7j/f4xgoO45jJxJDEAKehz+/vvNkqDWaLJdq1gbc2FCWlPinhmxFKuDQFgu+IgLnmdoK2z3aYqGPLkvVOpu1hrUcQZBmZQvr9pwNcJ5ZEF3aoob86nJ1s069qeznCHzpsmLNcHYiMQQhMDvqKGquz4DzFmRbik2nhKnhHPN+JqnFSAVgZjjX93mBfWrIizz6yWbbu81n0owWMn0XNXCjTouLx8xIvq8TBB3UkCXZPF32k82LZmx53sPuyW4LA2jUPSSGIAS8ATS/tvOAW2xxpBY975E8c33kAq+aya5ca+V637zKwkaVbFoYzUfqh+gbs54u+xjPli4tRlGzI3l/Rt26Lp0cQb+8ysJ6leFc2vjBR225nGcwt7bzM1toFSTYWXBFhNnRfN/1AhwjZVOXHhJDEAIzPhcPz4u0NeAAZ8D59LytepGjXtje75k5lJU9vjuYUbdFDYHzzPpFKkop5mOICJqqPwW5aHlRmx31R9nGMS9nRvrrstFULG7YK0joRGIIQmA4n2Eom/YRgtoNjcFf2F6u2a3Vh/Yz6GcIbCbXwamLz6Sk7zObt1hu62F2pL8XuV6pU603LecI/FIw9hKy0F7Y+8m1aLmaCfxF6sulKk1ll0HwkBiCkJgZzfXlbxctJ8vACdvn1io7ltDFQln59NbmLS8eqZQwPZLzvXjYju785y7s0nydf7sX5tftlWiCs8dhopj1ERF4BQk2ddk/d2e73LYTkQyBiEyJyOdE5JT7/2SXe35YRJ7o+FcWkXe7r/2BiJzpeO3eKPLYxIwP/rZVq2/x2LnZ0TyVenPHfvG2E58AMz4rrRbcUkib8KPLxY0quUyKEUu5C3CM+lq5vmO/oYUYNiC1qdF+xtNuZRq4uvSRIxjN263Vnx3Js7hR2TGv0o46b7yI4APAo0qp48Cj7u9boJT6olLqXqXUvcBbgBLw/3Xc8i+815VST0SUxxr8UDA2+wx58JO/mN+IIVIZ9cJ2H9SQZY7Ury5t9Rny4GfB9Z6nTePZrs7prUulHL7bZk4FHNn8RHfW5Rp18io7bcRbaOnyBosIgAeAj7s/fxx4d5/73wP8tVKqFPHvxg5fi4fFPkMe2pUTvWWLY8AVc05eZSc6bbPaoFS1V6vvYXok15eLn49Bl+3kZ//FY9DyKqvlOrWGGkijPh9T1On97V6wve+iE1ENwV6l1GX35yvA3j73vxf4423Xfl1EvisiHxKRnk9ARB4SkZMicnJubi6CyHow66OE7upqhb1jBYtS+aucWIwhIgAnKtjZu3Xruy2HxrMjeeY3qjvmVa6uVtg7aleXfiqa4uC7RZy8yk5GvaXLAaT5rq6W2TtmeYyN+nDQYqCSPfQ1BCLyeRF5qsu/BzrvU84s6jmTRGQ/ziH2n+24/EHgTuD7gCngF3u9Xyn1sFLqhFLqxOzsbD+xjcNPqHdttcyeuBaPHSbp3FrFam8aDzMj+R031VxdLQOwd9z+M6vWmzue43Bttcwey0bdS7DvlDCeX6/E0pum34J7dcXVZQyO0Hpl57zKtbXKQM7L+fUKU8N5q1Syh76ZL6XU/b1eE5GrIrJfKXXZXeiv7fBRPw78uVKq1dSlI5qoiMjHgF/wKXfs6FTsbJeuj82m4tpaxbrnMTWcIyU7ex5XVivsGy9Y5bvBSYJdWOrNCl5ddWS2/cxa+Yu1CmOF672xWqPJwkbVvlwjbbl64cpqmX2WF1twosmdFrWra54hiOeZza1VODxVvO71UrXOWrnOnrh0ucMzu7JiP1LxEJUaegR40P35QeAvd7j3fWyjhVzjgTgr0ruBpyLKYw3TfWqWl0pV6k1l3SNy2kz0maQrZetyAewZ27mWuhURxOatdfdwPZlte5H5TJqxQmbnxcM16raxZ7SfLt1nZjuK6uN5X1uNR5cj+QyFbKq/gxbDvITohuA3gLeJyCngfvd3ROSEiHzYu0lEjgGHgS9ve/8ficj3gO8BM8CvRZTHGryF1Bvw29GaCBZ6xG+Ht5egF66uxeNF7h8rsLBR7Rm2X10tk8ukrB/c7S0KniHajpaBisFb67e7+OqKffoRYP94gWtrFeqNZtfXr66WGclnrJbbQluX13qMf++6bV2KSH86bbVsnRb1EElLSqkF4K1drp8Efqbj95eBg13ue0uUvx8nPC/syspm19e90Ni2RwSOkeploJRSXFkp8yOvtC+X98yurVY4Mn192O4l8WxTVvsnHLku99Ble/GIQZejvXXZaCrm1ivsG7dvoPaNF2g0FfPr1a4RSRwJWejQ5XKPedky6vFEUVdWujsblXqDxY3qDRsR7FoUsmmmhnNc6qHYazF6kQcmCj0XtZXNGpV6M5aJsH98COi94MZRmQMwms8wnEtzuY8ubfPK4CxsvRa1hXVng1Ici4f3N3fUZRy5i+EcuXSKy32iuzgi9QMTQ72djZjyYx4SQxAB+8cLPS28p9huiWTT2D8+xPx6dwrmSowGqhVF7TBJ41g8RIT9E0NcXu4lV4WUxLPj88D4EFdWy10pmCsxerftiHjwdLlvvNBTl3NrFXKZVOvsZZs4MDHEpZVy1zLlOCMVSAxBJOwfL/T0Ii+vlpkazlkv6wNnwEH3Sepdi8WLHPe8yN6LRxxeN7i67GGgLrs8vK3T3Dqxf6JAU3XnvFu6jIFX9qK7bkZdKcW1mCIC8OZld8/78ko89CM4clXrza4l1N5zjEOXkBiCSNg/3jvUu7C0yaHJIcsSOTjgDqZLXWSL0/MYyWcYzWe6GqiVzRob1UZsHOn+8d4UzMXlUny6nOhNp111jUMcz2yymCWXSXXV5fx6lWqjyb44jXoPZ+PCUonDk9fnp2ygpcsu0UqcDhokhiAS9o0XWC7V2OxyRuqFpfgWj/3ugLvUZcBdXC6TkvhC0H096LTzi87+giNdar9tYP/4EHPrFar16ymY84txGvUddLm0STYtsbQkEJGeC+55d69Itzp+G9g/McTV1TLNLrv+43XQXF12MeqXlssMZdOxUFaQGIJIONCj2qTZVFxY2ozN89jvUTBdPNzziyX2jw+Ry8Sj+v0TQ1zsIteFuBeP8QJKwbW1rQtbvdHkymqZQ3Hp0h1jl3ro8vBkMRbKChzvtZdcEJ8uD4wXqDXUdXsJyrUG19YqA6nLc4sbHJkqxkJZQWIIIsGz8BeWtip23vUs4/I8Ctk008O5rp7HucVSbF43wNGpIi8vbFyXMDu/6Mgal/E8ONldl5dXyjSaisNT8ehyrJBlJJ/p6nmfXdyIbbEFODpd5Ozi9TvFW4YgZgrmwrYF11uA45qX08M5cplUV12eWyx1Lam2hcQQRMAtM8MAvLywseX6+SVvwMWn2ENTRc51maRnF2I2BNNF1sp1lku1LdfPLZYYLWQYt7yZzMOxaVeX81t1eWEQdDk51FWX52LW5bGZYebWKtedfXF+cZOZkTxDlntZdcoF1+sy7nkpIhyaHOLstvVCKRW7g5YYggiYHc0znEtz5rrFw5m0cXkeALfODHNmbqtcpWqd+fXum7lsobXgXmc840vigeNF5tKpgdTlbbMjvDS3vuXaSqnGarkeryFwdbl9YTu/VIotggInEkkJPXUZp2y3zoxcJ9fceoVyrcnRJCK4MSEiHJsZvk6xXmh8MGZDcGmlTKna9tY8+iVeL9L522cXtnq452P2iNIp4eh0sasuU9Iul4wDt8wMc35pc0si++yiI2ecRt1buK7TZcxGPZdJcWiymy6d5HocLTk83DY7zMsLpS3t6+POqUBiCCLj2MzwdSHoi3MbHBgvUMzZ7bPSiVtnR4CtXpHnucW54B6aLCKyNSKoN5qcX9qMdVEDV5cL1+vyyFQxtuQ6wK2zwzSainOLbdnOxVxlBXC0S3RXqTe4tFyO1bsFx3huNwSnr61zy8xwbMl1cHRZrTe52JGL8gxpQg3dwLhl2vHWah07P09dW+P2vaMxStXOX3ROhtMuvXDL7HAsMoGTyD4wPrTFeJ5dLFGtN3lFzM/s1hnHW+ssOzx1bY3b98Qsl2vUX+yg+k5dXUekTc/EgZF8hpmR/BZdvjS3QaOpOD4A4//l+a1FCaevrXE8Zl3eMuPqcr5N9Z26tk42LbFGUYkhiAjPW/O87WZTcfraOsf3jMQql2cIXupYPJ67vMbBiaGuPfdt4vY9Izx3Za31+wvuz3cMwOJRrTdbCeJao8mZ+Q1uj1mXt85er8vnr6xxy/RwbAlZD8f3jPB8py6vOj+/Ym/843+j2mg17CvXGpxbLA2sLm+bHYk16kwMQUTcfWAMgKcurgKOd1uuNWOfCEO5NEenizx7ebV17bkrq9y5L97FFuCVB8Y4fW2dSt3ZiPf81TVEiH2StnR5aQWAF+fWqTVU7LocK2TZP17guStbdXnHgOjyuStrrV5Iz19ZI52SliMSp1wAT110dHnq6jpNRexR5/Rwjunh3NZ5eTl+XSaGICJunx2hkE3x3QvOgHvi/BIA9xyeiFEqB/ccmuDJ88uAUzH04twGd+0fi1co4JUHxqk3FS9cccLjJ84vc/vsSOze7R37Rsmmpa3Lc8sA3DsgunzC1eXKZo2zi6XB0OXBMSr1Zou2euL8MnfuG42lx1Yn7j4wRkrgu64heNydl/cemYhRKqfA5J7D7Xm5sF7h0ko5dl0mhiAiMukUrzwwzn895wy0x88tM5xLx85FgmOMLq2Uubpa5jtnl2g0Fd93y1TcYrUm42MvL9JsKv7r2SVOHJuMVyicE8Hu2De6RZfjQ9nYvVtwdHl2ocTiRpWTLy+iFHzfsfh1ec+hCcDRZb3R5Inzy5w4Gr8ui7kMx/eM8riryyfOLTM7mm/14YoT9xya4PTcOqvlGt8+swjEr8tIhkBE/p6IPC0iTRE5scN97xCR50XktIh8oOP6LSLyLff6n4hILoo8ceEHb5/hyQvLLG5U+fILc5w4NhVrZYKHN946DcCXnr/GN15cIJ0SXjcAk/TgxBC3zgzz1VNzPHVphdVynRNH41/UAH7w9ln+69klVjZrfOXUHK+/ZSq2bf+deMOtzvP58guOLnPpFPfF7N2Cw8UfnBjiq6fmeOL8MqVqgxMDYKAA3nT7DN86s8haucZXTs0PlC6Vgq++MM/XX1xgKJvm1QfHY5UpakTwFPA/AF/pdYOIpIHfAd4J3A28T0Tudl/+TeBDSqnbgSXg/RHliQVvuXMPSsG//cyznF0o8c5X7YtbJADu2j/K4akhHnnyEn/++EV+4LZp60cH9sKb79jD355e4Pe//BK5dIr779obt0gAvPWuPdSbil/79DNcXikPjC7vOTTB3rE8f/H4Jf7iiUv80CtmKGTjpV/AoTrefMcsX35hjo987QyFbIofvnNP3GIBji6r9Sb/+r88w/x6ZWB0eeLYFNPDOf788Qt8+ruXePMds7EmiiGiIVBKPauUer7Pba8HTiulXlJKVYFPAg+4B9a/BfiUe9/HcQ6wv+HwmkPjnDg6yZ995wKjhQzvfNX+uEUCnEn6EycO87enF7i8UuYn33A0bpFaePAHjlJvNvmr713mna/eF1trie04cXSSew5P8GffucBEMcvb7h4MA5VKCT/xfUf48gtzzK9XBkqXP/2mW6jUm/z1U1f4715zYGCcjTfcOs3d+8f41HcuMDOS4y0DYqDSKeE9Jw7x+WevsVSq8Q8GQJc2NHYQON/x+wXg+4FpYFkpVe+4ft25xh5E5CHgIYAjR46YkTQkRIT/68fv4eGvvMS77jkwMIsawEM/dBuVepOJYo63D8iiBs5mpP/w91/Lt88s8k/fejxucVoQET704/fw4a+d4cdee5DRmEttO/GzP3wb9YZzzOib7xiMRQ2caq/f+ol7eeL8Mv/sra+IW5wW0inht993Lx/52sv8+IlDsW7w3I5/fv8rEITDU0P8wO0zcYuDdDs2bcsNIp8HusVUv6SU+kv3ni8Bv+AeWr/9/e8B3qGU+hn393+AYwj+FfBNlxZCRA4Df62UelU/oU+cOKFOnrzuTyVIkCBBgh0gIt9RSl2Xz+1rIpVS90f82xeBwx2/H3KvLQATIpJxowLveoIECRIksAgbGYrHgONuhVAOeC/wiHJCkS8C73HvexD4SwvyJEiQIEGCDkQtH/3vReQC8Ebgr0Tks+71AyLyGQDX2/854LPAs8CfKqWedj/iF4GfF5HTODmDj0SRJ0GCBAkSBEffHMEgIskRJEiQIEFw9MoRJDuLEyRIkGCXIzEECRIkSLDLkRiCBAkSJNjlSAxBggQJEuxy3JDJYhGZA86GfPsMMK9RnBsByXfeHUi+8+5AlO98VCk1u/3iDWkIokBETnbLmt/MSL7z7kDynXcHTHznhBpKkCBBgl2OxBAkSJAgwS7HbjQED8ctQAxIvvPuQPKddwe0f+ddlyNIkCBBggRbsRsjggQJEiRI0IHEECRIkCDBLseuMgQi8g4ReV5ETovIB+KWRwdE5LCIfFFEnhGRp0Xkn7rXp0TkcyJyyv1/0r0uIvLb7jP4roi8Nt5vEB4ikhaRx0Xk0+7vt4jIt9zv9idu23NEJO/+ftp9/VisgoeEiEyIyKdE5DkReVZE3niz61lE/rk7rp8SkT8WkcLNqGcR+aiIXBORpzquBdatiDzo3n9KRB70+/d3jSEQkTTwO8A7gbuB94nI3fFKpQV14H9VSt0NvAH4Wfd7fQB4VCl1HHjU/R2c73/c/fcQ8Lv2RdaGf4rT2tzDbwIfck+9WwLe715/P7DkXv+Qe9+NiH8P/I1S6k7gHpzvftPqWUQOAv8EOOGeXJjGOc/kZtTzHwDv2HYtkG5FZAr4FZwTIF8P/IpnPPpCKbUr/uGcmfDZjt8/CHwwbrkMfM+/BN4GPA/sd6/tB553f/594H0d97fuu5H+4Zxo9yjwFuDTgODstsxs1zfOWRhvdH/OuPdJ3N8h4PcdB85sl/tm1jPt886nXL19GviRm1XPwDHgqbC6Bd4H/H7H9S337fRv10QEtAeVhwvutZsGbih8H/AtYK9S6rL70hXAO7n+ZnkOvwX8S6Dp/j4NLCvnICTY+r1a39l9fcW9/0bCLcAc8DGXDvuwiAxzE+tZKXUR+D+Bc8BlHL19h5tbz50IqtvQOt9NhuCmhoiMAP8J+GdKqdXO15TjHtw0dcIi8t8C15RS34lbFovIAK8FflcpdR+wQZsqAG5KPU8CD+AYwQPAMNfTJ7sCpnW7mwzBReBwx++H3Gs3PEQki2ME/kgp9Z/dy1dFZL/7+n7gmnv9ZngObwLeJSIvA5/EoYf+PTAhIhn3ns7v1frO7uvjwIJNgTXgAnBBKfUt9/dP4RiGm1nP9wNnlFJzSqka8J9xdH8z67kTQXUbWue7yRA8Bhx3Kw5yOEmnR2KWKTJERHDOen5WKfXvOl56BPCqBh7EyR141/+hW3nwBmClI/y8IaCU+qBS6pBS6hiOHr+glPofgS8C73Fv2/6dvWfxHvf+G8pzVkpdAc6LyB3upbcCz3AT6xmHEnqDiBTdce5955tWz9sQVLefBd4uIpNuNPV291p/xJ0gsZyM+VHgBeBF4JfilkfTd/pBnJDxu8AT7r8fxeFGHwVOAZ8Hptz7Bad66kXgezgVGbF/jwjf/83Ap92fbwW+DZwG/gzIu9cL7u+n3ddvjVvukN/1XuCkq+u/ACZvdj0D/xp4DngK+ASQvxn1DPwxTh6khhP9vT+MboF/5H7/08BP+/37SYuJBAkSJNjl2E3UUIIECRIk6ILEECRIkCDBLkdiCBIkSJBglyMxBAkSJEiwy5EYggQJEiTY5UgMQYIECRLsciSGIEGCBAl2Of5/fq7z1qKFhFIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_input = torch.from_numpy(y[3:, :-1]) # (97, 999)\n",
    "train_target = torch.from_numpy(y[3:, 1:]) # (97, 999)\n",
    "test_input = torch.from_numpy(y[:3, :-1]) # (3, 999)\n",
    "test_target = torch.from_numpy(y[:3, 1:]) # (3, 999)\n",
    "plt.plot(train_target[4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5d7b886-1252-4836-94c1-6cc4b70cb490",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM()\n",
    "criterion = nn.MSELoss()\n",
    "optimiser = optim.LBFGS(model.parameters(), lr=0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8229748-5382-443e-a66f-96db69226da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, model, optimiser, loss_fn, \n",
    "                  train_input, train_target, test_input, test_target):\n",
    "    for i in range(n_epochs):\n",
    "        def closure():\n",
    "            optimiser.zero_grad()\n",
    "            out = model(train_input)\n",
    "            loss = loss_fn(out, train_target)\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        optimiser.step(closure)\n",
    "        with torch.no_grad():\n",
    "            future = 1000\n",
    "            pred = model(test_input, future=future)\n",
    "            # use all pred samples, but only go to 999\n",
    "            loss = loss_fn(pred[:, :-future], test_target)\n",
    "            y = pred.detach().numpy()\n",
    "        # draw figures\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.title(f\"Step {i+1}\")\n",
    "        plt.xlabel(\"x\")\n",
    "        plt.ylabel(\"y\")\n",
    "        plt.xticks(fontsize=20)\n",
    "        plt.yticks(fontsize=20)\n",
    "        n = train_input.shape[1] # 999\n",
    "        def draw(yi, colour):\n",
    "            plt.plot(np.arange(n), yi[:n], colour, linewidth=2.0)\n",
    "            plt.plot(np.arange(n, n+future), yi[n:], colour+\":\", linewidth=2.0)\n",
    "        draw(y[0], 'r')\n",
    "        draw(y[1], 'b')\n",
    "        draw(y[2], 'g')\n",
    "        plt.savefig(\"predict%d.png\"%i, dpi=200)\n",
    "        plt.close()\n",
    "        # print the loss\n",
    "        out = model(train_input)\n",
    "        loss_print = loss_fn(out, train_target)\n",
    "        print(\"Step: {}, Loss: {}\".format(i, loss_print))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e2185fb-382b-4a99-8612-4647534a9344",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m              \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m              \u001b[49m\u001b[43moptimiser\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimiser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m              \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtrain_input\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtest_input\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtest_target\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_target\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36mtraining_loop\u001b[1;34m(n_epochs, model, optimiser, loss_fn, train_input, train_target, test_input, test_target)\u001b[0m\n\u001b[0;32m      8\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[1;32m---> 10\u001b[0m \u001b[43moptimiser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     12\u001b[0m     future \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bgpredict-zZmw8Ikr-py3.10\\lib\\site-packages\\torch\\optim\\optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bgpredict-zZmw8Ikr-py3.10\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bgpredict-zZmw8Ikr-py3.10\\lib\\site-packages\\torch\\optim\\lbfgs.py:311\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    308\u001b[0m state\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_iter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m# evaluate initial f(x) and df/dx\u001b[39;00m\n\u001b[1;32m--> 311\u001b[0m orig_loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    312\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(orig_loss)\n\u001b[0;32m    313\u001b[0m current_evals \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bgpredict-zZmw8Ikr-py3.10\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36mtraining_loop.<locals>.closure\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m():\n\u001b[0;32m      5\u001b[0m     optimiser\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 6\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(out, train_target)\n\u001b[0;32m      8\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\bgpredict-zZmw8Ikr-py3.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1129\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1128\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, y, future_preds)\u001b[0m\n\u001b[0;32m     16\u001b[0m c_t2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(n_samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_layers, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m time_step \u001b[38;5;129;01min\u001b[39;00m y\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;241m1\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# N, 1\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     h_t, c_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm1(\u001b[43minput_t\u001b[49m, (h_t, c_t)) \u001b[38;5;66;03m# initial hidden and cell states\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     h_t2, c_t2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm2(h_t, (h_t2, c_t2)) \u001b[38;5;66;03m# new hidden and cell states\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(h_t2) \u001b[38;5;66;03m# output from the last FC layer\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_t' is not defined"
     ]
    }
   ],
   "source": [
    "training_loop(n_epochs = 10,\n",
    "              model = model,\n",
    "              optimiser = optimiser,\n",
    "              loss_fn = criterion,\n",
    "              train_input = train_input,\n",
    "              train_target = train_target,\n",
    "              test_input = test_input,\n",
    "              test_target = test_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry_kernel",
   "language": "python",
   "name": "poetry_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
